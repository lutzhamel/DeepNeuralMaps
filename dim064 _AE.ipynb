{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder for dim064 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1467: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Model,load_model\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import regularizers\n",
    "from keras.layers import Input, Dense, Conv1D, MaxPooling1D, UpSampling1D\n",
    "from keras.models import Model\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "x_train = pd.read_csv('dataset/dim064_train.csv')\n",
    "x_test = pd.read_csv('dataset/dim064_test.csv')\n",
    "#y_train = pd.read_csv('dataset/dim064_train_label.csv')\n",
    "#y_train = np.asarray(y_train)\n",
    "#y_test = pd.read_csv('dataset/dim064_test_label.csv')\n",
    "#y_test = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Normalization\n",
    "# #x_train.max().max()\n",
    "# x_train = x_train.astype('float32') / 157.\n",
    "# x_test = x_test.astype('float32') / 157."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_42 (InputLayer)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 12)                780       \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 64)                832       \n",
      "=================================================================\n",
      "Total params: 1,612\n",
      "Trainable params: 1,612\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "########### Basic Autoencoder ##########\n",
    "input_dim = x_train.shape[1]\n",
    "input_layer = Input(shape=(input_dim, ))\n",
    "\n",
    "encoding_dim = 12\n",
    "#learning_rate = 1e-7\n",
    "\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
    "\n",
    "# implenment an autoencoder, creat encoder and decoder\n",
    "\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "\n",
    "encoder = Model(input_layer, encoded)\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "                                             \n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_train = autoencoder.fit(x_train, x_train,\n",
    "                epochs=200,\n",
    "                batch_size=128,\n",
    "                shuffle=False,\n",
    "                validation_data=(x_test, x_test),\n",
    "                verbose = 0\n",
    "                ).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# AE loss\n",
    "plt.plot(ae_train['loss'])\n",
    "plt.plot(ae_train['val_loss'])\n",
    "plt.title('AE model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create encoded data\n",
    "encoded_data = encoder.predict(x_test)\n",
    "#decoded_data = decoder.predict(encoded_data)\n",
    "\n",
    "# transform to SOM input type\n",
    "encoded_som = pd.DataFrame(encoded_data)\n",
    "#decoded_som = pd.DataFrame(decoded_data)\n",
    "\n",
    "# get rid of columns with all zeros\n",
    "nonzero = list(map(lambda i: any(encoded_data[:,i] != 0), range(encoded_data.shape[1])))\n",
    "encoded_som_nonzero = pd.DataFrame(encoded_data[:,nonzero])\n",
    "encoded_som_nonzero.to_csv(path_or_buf='output/dim064_AE_encoded.csv',index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Sparse Autoencoder ##########\n",
    "input_dim = x_train.shape[1]\n",
    "input_layer = Input(shape=(input_dim, ))\n",
    "\n",
    "encoding_dim = 12\n",
    "#learning_rate = 1e-7\n",
    "\n",
    "encoded = Dense(encoding_dim, activation='relu', activity_regularizer=regularizers.l1(10e-7))(input_layer)\n",
    "\n",
    "decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
    "\n",
    "# implenment an autoencoder, creat encoder and decoder\n",
    "\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "\n",
    "encoder = Model(input_layer, encoded)\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "                                             \n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 12)                780       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                832       \n",
      "=================================================================\n",
      "Total params: 1,612\n",
      "Trainable params: 1,612\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 614 samples, validate on 410 samples\n",
      "Epoch 1/200\n",
      "614/614 [==============================] - 1s 1ms/step - loss: 0.0656 - val_loss: 0.0635\n",
      "Epoch 2/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0625 - val_loss: 0.0610\n",
      "Epoch 3/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0603 - val_loss: 0.0592\n",
      "Epoch 4/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0587 - val_loss: 0.0580\n",
      "Epoch 5/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0576 - val_loss: 0.0571\n",
      "Epoch 6/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0568 - val_loss: 0.0566\n",
      "Epoch 7/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0563 - val_loss: 0.0561\n",
      "Epoch 8/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0558 - val_loss: 0.0556\n",
      "Epoch 9/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0553 - val_loss: 0.0552\n",
      "Epoch 10/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0549 - val_loss: 0.0547\n",
      "Epoch 11/200\n",
      "614/614 [==============================] - 0s 39us/step - loss: 0.0545 - val_loss: 0.0543\n",
      "Epoch 12/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0540 - val_loss: 0.0539\n",
      "Epoch 13/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0536 - val_loss: 0.0535\n",
      "Epoch 14/200\n",
      "614/614 [==============================] - 0s 33us/step - loss: 0.0532 - val_loss: 0.0531\n",
      "Epoch 15/200\n",
      "614/614 [==============================] - 0s 31us/step - loss: 0.0528 - val_loss: 0.0527\n",
      "Epoch 16/200\n",
      "614/614 [==============================] - 0s 27us/step - loss: 0.0524 - val_loss: 0.0523\n",
      "Epoch 17/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0520 - val_loss: 0.0520\n",
      "Epoch 18/200\n",
      "614/614 [==============================] - 0s 32us/step - loss: 0.0516 - val_loss: 0.0516\n",
      "Epoch 19/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0512 - val_loss: 0.0512\n",
      "Epoch 20/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0509 - val_loss: 0.0509\n",
      "Epoch 21/200\n",
      "614/614 [==============================] - 0s 33us/step - loss: 0.0505 - val_loss: 0.0506\n",
      "Epoch 22/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0502 - val_loss: 0.0502\n",
      "Epoch 23/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0498 - val_loss: 0.0499\n",
      "Epoch 24/200\n",
      "614/614 [==============================] - 0s 33us/step - loss: 0.0495 - val_loss: 0.0496\n",
      "Epoch 25/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0492 - val_loss: 0.0494\n",
      "Epoch 26/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0489 - val_loss: 0.0491\n",
      "Epoch 27/200\n",
      "614/614 [==============================] - 0s 39us/step - loss: 0.0486 - val_loss: 0.0488\n",
      "Epoch 28/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0483 - val_loss: 0.0485\n",
      "Epoch 29/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0481 - val_loss: 0.0483\n",
      "Epoch 30/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0478 - val_loss: 0.0480\n",
      "Epoch 31/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0475 - val_loss: 0.0478\n",
      "Epoch 32/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0473 - val_loss: 0.0475\n",
      "Epoch 33/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0470 - val_loss: 0.0473\n",
      "Epoch 34/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0467 - val_loss: 0.0470\n",
      "Epoch 35/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0465 - val_loss: 0.0467\n",
      "Epoch 36/200\n",
      "614/614 [==============================] - 0s 39us/step - loss: 0.0462 - val_loss: 0.0465\n",
      "Epoch 37/200\n",
      "614/614 [==============================] - 0s 39us/step - loss: 0.0459 - val_loss: 0.0462\n",
      "Epoch 38/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0457 - val_loss: 0.0459\n",
      "Epoch 39/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0454 - val_loss: 0.0457\n",
      "Epoch 40/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0451 - val_loss: 0.0454\n",
      "Epoch 41/200\n",
      "614/614 [==============================] - 0s 32us/step - loss: 0.0448 - val_loss: 0.0451\n",
      "Epoch 42/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0446 - val_loss: 0.0449\n",
      "Epoch 43/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0443 - val_loss: 0.0446\n",
      "Epoch 44/200\n",
      "614/614 [==============================] - 0s 33us/step - loss: 0.0440 - val_loss: 0.0443\n",
      "Epoch 45/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0437 - val_loss: 0.0441\n",
      "Epoch 46/200\n",
      "614/614 [==============================] - 0s 32us/step - loss: 0.0435 - val_loss: 0.0438\n",
      "Epoch 47/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0432 - val_loss: 0.0435\n",
      "Epoch 48/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0429 - val_loss: 0.0432\n",
      "Epoch 49/200\n",
      "614/614 [==============================] - 0s 39us/step - loss: 0.0426 - val_loss: 0.0429\n",
      "Epoch 50/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0423 - val_loss: 0.0427\n",
      "Epoch 51/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0420 - val_loss: 0.0424\n",
      "Epoch 52/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0417 - val_loss: 0.0421\n",
      "Epoch 53/200\n",
      "614/614 [==============================] - 0s 32us/step - loss: 0.0414 - val_loss: 0.0418\n",
      "Epoch 54/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0412 - val_loss: 0.0415\n",
      "Epoch 55/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0409 - val_loss: 0.0413\n",
      "Epoch 56/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0406 - val_loss: 0.0410\n",
      "Epoch 57/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0403 - val_loss: 0.0407\n",
      "Epoch 58/200\n",
      "614/614 [==============================] - 0s 32us/step - loss: 0.0400 - val_loss: 0.0404\n",
      "Epoch 59/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0397 - val_loss: 0.0402\n",
      "Epoch 60/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0395 - val_loss: 0.0399\n",
      "Epoch 61/200\n",
      "614/614 [==============================] - 0s 33us/step - loss: 0.0392 - val_loss: 0.0396\n",
      "Epoch 62/200\n",
      "614/614 [==============================] - 0s 32us/step - loss: 0.0389 - val_loss: 0.0394\n",
      "Epoch 63/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0386 - val_loss: 0.0391\n",
      "Epoch 64/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0384 - val_loss: 0.0388\n",
      "Epoch 65/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0381 - val_loss: 0.0386\n",
      "Epoch 66/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0379 - val_loss: 0.0383\n",
      "Epoch 67/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0376 - val_loss: 0.0381\n",
      "Epoch 68/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0373 - val_loss: 0.0379\n",
      "Epoch 69/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0371 - val_loss: 0.0376\n",
      "Epoch 70/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0369 - val_loss: 0.0374\n",
      "Epoch 71/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0366 - val_loss: 0.0372\n",
      "Epoch 72/200\n",
      "614/614 [==============================] - 0s 32us/step - loss: 0.0364 - val_loss: 0.0369\n",
      "Epoch 73/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0362 - val_loss: 0.0367\n",
      "Epoch 74/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0359 - val_loss: 0.0365\n",
      "Epoch 75/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0357 - val_loss: 0.0363\n",
      "Epoch 76/200\n",
      "614/614 [==============================] - 0s 33us/step - loss: 0.0355 - val_loss: 0.0361\n",
      "Epoch 77/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0353 - val_loss: 0.0359\n",
      "Epoch 78/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0351 - val_loss: 0.0357\n",
      "Epoch 79/200\n",
      "614/614 [==============================] - 0s 32us/step - loss: 0.0349 - val_loss: 0.0355\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614/614 [==============================] - 0s 40us/step - loss: 0.0347 - val_loss: 0.0353\n",
      "Epoch 81/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0345 - val_loss: 0.0351\n",
      "Epoch 82/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0343 - val_loss: 0.0349\n",
      "Epoch 83/200\n",
      "614/614 [==============================] - 0s 33us/step - loss: 0.0341 - val_loss: 0.0347\n",
      "Epoch 84/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0340 - val_loss: 0.0346\n",
      "Epoch 85/200\n",
      "614/614 [==============================] - 0s 32us/step - loss: 0.0338 - val_loss: 0.0344\n",
      "Epoch 86/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0336 - val_loss: 0.0342\n",
      "Epoch 87/200\n",
      "614/614 [==============================] - 0s 31us/step - loss: 0.0335 - val_loss: 0.0341\n",
      "Epoch 88/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0333 - val_loss: 0.0339\n",
      "Epoch 89/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0332 - val_loss: 0.0338\n",
      "Epoch 90/200\n",
      "614/614 [==============================] - 0s 32us/step - loss: 0.0330 - val_loss: 0.0336\n",
      "Epoch 91/200\n",
      "614/614 [==============================] - 0s 32us/step - loss: 0.0329 - val_loss: 0.0335\n",
      "Epoch 92/200\n",
      "614/614 [==============================] - 0s 33us/step - loss: 0.0327 - val_loss: 0.0334\n",
      "Epoch 93/200\n",
      "614/614 [==============================] - 0s 32us/step - loss: 0.0326 - val_loss: 0.0332\n",
      "Epoch 94/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0325 - val_loss: 0.0331\n",
      "Epoch 95/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0323 - val_loss: 0.0329\n",
      "Epoch 96/200\n",
      "614/614 [==============================] - 0s 33us/step - loss: 0.0322 - val_loss: 0.0328\n",
      "Epoch 97/200\n",
      "614/614 [==============================] - 0s 32us/step - loss: 0.0321 - val_loss: 0.0327\n",
      "Epoch 98/200\n",
      "614/614 [==============================] - 0s 32us/step - loss: 0.0320 - val_loss: 0.0326\n",
      "Epoch 99/200\n",
      "614/614 [==============================] - 0s 33us/step - loss: 0.0318 - val_loss: 0.0324\n",
      "Epoch 100/200\n",
      "614/614 [==============================] - 0s 32us/step - loss: 0.0317 - val_loss: 0.0323\n",
      "Epoch 101/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0316 - val_loss: 0.0322\n",
      "Epoch 102/200\n",
      "614/614 [==============================] - 0s 32us/step - loss: 0.0315 - val_loss: 0.0321\n",
      "Epoch 103/200\n",
      "614/614 [==============================] - 0s 33us/step - loss: 0.0314 - val_loss: 0.0320\n",
      "Epoch 104/200\n",
      "614/614 [==============================] - 0s 32us/step - loss: 0.0313 - val_loss: 0.0319\n",
      "Epoch 105/200\n",
      "614/614 [==============================] - 0s 33us/step - loss: 0.0312 - val_loss: 0.0318\n",
      "Epoch 106/200\n",
      "614/614 [==============================] - 0s 32us/step - loss: 0.0311 - val_loss: 0.0317\n",
      "Epoch 107/200\n",
      "614/614 [==============================] - 0s 33us/step - loss: 0.0310 - val_loss: 0.0316\n",
      "Epoch 108/200\n",
      "614/614 [==============================] - 0s 32us/step - loss: 0.0310 - val_loss: 0.0315\n",
      "Epoch 109/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0309 - val_loss: 0.0314\n",
      "Epoch 110/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0308 - val_loss: 0.0314\n",
      "Epoch 111/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0307 - val_loss: 0.0313\n",
      "Epoch 112/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0306 - val_loss: 0.0312\n",
      "Epoch 113/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0306 - val_loss: 0.0311\n",
      "Epoch 114/200\n",
      "614/614 [==============================] - 0s 39us/step - loss: 0.0305 - val_loss: 0.0310\n",
      "Epoch 115/200\n",
      "614/614 [==============================] - 0s 32us/step - loss: 0.0304 - val_loss: 0.0310\n",
      "Epoch 116/200\n",
      "614/614 [==============================] - 0s 31us/step - loss: 0.0304 - val_loss: 0.0309\n",
      "Epoch 117/200\n",
      "614/614 [==============================] - 0s 32us/step - loss: 0.0303 - val_loss: 0.0308\n",
      "Epoch 118/200\n",
      "614/614 [==============================] - 0s 31us/step - loss: 0.0302 - val_loss: 0.0308\n",
      "Epoch 119/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0302 - val_loss: 0.0307\n",
      "Epoch 120/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0301 - val_loss: 0.0306\n",
      "Epoch 121/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0301 - val_loss: 0.0306\n",
      "Epoch 122/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0300 - val_loss: 0.0305\n",
      "Epoch 123/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0299 - val_loss: 0.0304\n",
      "Epoch 124/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0299 - val_loss: 0.0304\n",
      "Epoch 125/200\n",
      "614/614 [==============================] - 0s 63us/step - loss: 0.0298 - val_loss: 0.0303\n",
      "Epoch 126/200\n",
      "614/614 [==============================] - 0s 44us/step - loss: 0.0298 - val_loss: 0.0303\n",
      "Epoch 127/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0297 - val_loss: 0.0302\n",
      "Epoch 128/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0297 - val_loss: 0.0301\n",
      "Epoch 129/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0296 - val_loss: 0.0301\n",
      "Epoch 130/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0296 - val_loss: 0.0300\n",
      "Epoch 131/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0295 - val_loss: 0.0300\n",
      "Epoch 132/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0295 - val_loss: 0.0299\n",
      "Epoch 133/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0294 - val_loss: 0.0299\n",
      "Epoch 134/200\n",
      "614/614 [==============================] - 0s 40us/step - loss: 0.0294 - val_loss: 0.0298\n",
      "Epoch 135/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0293 - val_loss: 0.0298\n",
      "Epoch 136/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0293 - val_loss: 0.0297\n",
      "Epoch 137/200\n",
      "614/614 [==============================] - 0s 32us/step - loss: 0.0292 - val_loss: 0.0297\n",
      "Epoch 138/200\n",
      "614/614 [==============================] - 0s 32us/step - loss: 0.0292 - val_loss: 0.0296\n",
      "Epoch 139/200\n",
      "614/614 [==============================] - 0s 31us/step - loss: 0.0291 - val_loss: 0.0296\n",
      "Epoch 140/200\n",
      "614/614 [==============================] - 0s 32us/step - loss: 0.0291 - val_loss: 0.0295\n",
      "Epoch 141/200\n",
      "614/614 [==============================] - 0s 33us/step - loss: 0.0290 - val_loss: 0.0295\n",
      "Epoch 142/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0290 - val_loss: 0.0294\n",
      "Epoch 143/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0290 - val_loss: 0.0294\n",
      "Epoch 144/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0289 - val_loss: 0.0293\n",
      "Epoch 145/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0289 - val_loss: 0.0293\n",
      "Epoch 146/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0288 - val_loss: 0.0292\n",
      "Epoch 147/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0288 - val_loss: 0.0292\n",
      "Epoch 148/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0287 - val_loss: 0.0291\n",
      "Epoch 149/200\n",
      "614/614 [==============================] - 0s 26us/step - loss: 0.0287 - val_loss: 0.0291\n",
      "Epoch 150/200\n",
      "614/614 [==============================] - 0s 29us/step - loss: 0.0287 - val_loss: 0.0290\n",
      "Epoch 151/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0286 - val_loss: 0.0290\n",
      "Epoch 152/200\n",
      "614/614 [==============================] - 0s 39us/step - loss: 0.0286 - val_loss: 0.0290\n",
      "Epoch 153/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0285 - val_loss: 0.0289\n",
      "Epoch 154/200\n",
      "614/614 [==============================] - 0s 40us/step - loss: 0.0285 - val_loss: 0.0289\n",
      "Epoch 155/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0284 - val_loss: 0.0288\n",
      "Epoch 156/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0284 - val_loss: 0.0288\n",
      "Epoch 157/200\n",
      "614/614 [==============================] - 0s 33us/step - loss: 0.0284 - val_loss: 0.0287\n",
      "Epoch 158/200\n",
      "614/614 [==============================] - 0s 29us/step - loss: 0.0283 - val_loss: 0.0287\n",
      "Epoch 159/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614/614 [==============================] - 0s 35us/step - loss: 0.0283 - val_loss: 0.0287\n",
      "Epoch 160/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0282 - val_loss: 0.0286\n",
      "Epoch 161/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0282 - val_loss: 0.0286\n",
      "Epoch 162/200\n",
      "614/614 [==============================] - 0s 31us/step - loss: 0.0282 - val_loss: 0.0285\n",
      "Epoch 163/200\n",
      "614/614 [==============================] - 0s 32us/step - loss: 0.0281 - val_loss: 0.0285\n",
      "Epoch 164/200\n",
      "614/614 [==============================] - 0s 32us/step - loss: 0.0281 - val_loss: 0.0285\n",
      "Epoch 165/200\n",
      "614/614 [==============================] - 0s 30us/step - loss: 0.0281 - val_loss: 0.0284\n",
      "Epoch 166/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0280 - val_loss: 0.0284\n",
      "Epoch 167/200\n",
      "614/614 [==============================] - 0s 32us/step - loss: 0.0280 - val_loss: 0.0283\n",
      "Epoch 168/200\n",
      "614/614 [==============================] - 0s 32us/step - loss: 0.0279 - val_loss: 0.0283\n",
      "Epoch 169/200\n",
      "614/614 [==============================] - 0s 33us/step - loss: 0.0279 - val_loss: 0.0283\n",
      "Epoch 170/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0279 - val_loss: 0.0282\n",
      "Epoch 171/200\n",
      "614/614 [==============================] - 0s 29us/step - loss: 0.0278 - val_loss: 0.0282\n",
      "Epoch 172/200\n",
      "614/614 [==============================] - 0s 32us/step - loss: 0.0278 - val_loss: 0.0281\n",
      "Epoch 173/200\n",
      "614/614 [==============================] - 0s 32us/step - loss: 0.0277 - val_loss: 0.0281\n",
      "Epoch 174/200\n",
      "614/614 [==============================] - 0s 30us/step - loss: 0.0277 - val_loss: 0.0281\n",
      "Epoch 175/200\n",
      "614/614 [==============================] - 0s 33us/step - loss: 0.0277 - val_loss: 0.0280\n",
      "Epoch 176/200\n",
      "614/614 [==============================] - 0s 33us/step - loss: 0.0276 - val_loss: 0.0280\n",
      "Epoch 177/200\n",
      "614/614 [==============================] - 0s 31us/step - loss: 0.0276 - val_loss: 0.0280\n",
      "Epoch 178/200\n",
      "614/614 [==============================] - 0s 31us/step - loss: 0.0276 - val_loss: 0.0279\n",
      "Epoch 179/200\n",
      "614/614 [==============================] - 0s 33us/step - loss: 0.0275 - val_loss: 0.0279\n",
      "Epoch 180/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0275 - val_loss: 0.0278\n",
      "Epoch 181/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0275 - val_loss: 0.0278\n",
      "Epoch 182/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0274 - val_loss: 0.0278\n",
      "Epoch 183/200\n",
      "614/614 [==============================] - 0s 33us/step - loss: 0.0274 - val_loss: 0.0277\n",
      "Epoch 184/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0274 - val_loss: 0.0277\n",
      "Epoch 185/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0273 - val_loss: 0.0277\n",
      "Epoch 186/200\n",
      "614/614 [==============================] - 0s 40us/step - loss: 0.0273 - val_loss: 0.0276\n",
      "Epoch 187/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0273 - val_loss: 0.0276\n",
      "Epoch 188/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0272 - val_loss: 0.0276\n",
      "Epoch 189/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0272 - val_loss: 0.0275\n",
      "Epoch 190/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0272 - val_loss: 0.0275\n",
      "Epoch 191/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0271 - val_loss: 0.0275\n",
      "Epoch 192/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0271 - val_loss: 0.0274\n",
      "Epoch 193/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0271 - val_loss: 0.0274\n",
      "Epoch 194/200\n",
      "614/614 [==============================] - 0s 28us/step - loss: 0.0270 - val_loss: 0.0274\n",
      "Epoch 195/200\n",
      "614/614 [==============================] - 0s 29us/step - loss: 0.0270 - val_loss: 0.0274\n",
      "Epoch 196/200\n",
      "614/614 [==============================] - 0s 29us/step - loss: 0.0270 - val_loss: 0.0273\n",
      "Epoch 197/200\n",
      "614/614 [==============================] - 0s 32us/step - loss: 0.0269 - val_loss: 0.0273\n",
      "Epoch 198/200\n",
      "614/614 [==============================] - 0s 33us/step - loss: 0.0269 - val_loss: 0.0273\n",
      "Epoch 199/200\n",
      "614/614 [==============================] - 0s 31us/step - loss: 0.0269 - val_loss: 0.0272\n",
      "Epoch 200/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0269 - val_loss: 0.0272\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ae_train = autoencoder.fit(x_train, x_train,\n",
    "                epochs=200,\n",
    "                batch_size=128,\n",
    "                shuffle=False,\n",
    "                validation_data=(x_test, x_test)\n",
    "                ).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SAE loss\n",
    "plt.plot(ae_train['loss'])\n",
    "plt.plot(ae_train['val_loss'])\n",
    "plt.title('SAE model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.035916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.009271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.026856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.028645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.031669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.042094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.065571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  200.000000\n",
       "mean     0.035916\n",
       "std      0.009271\n",
       "min      0.026856\n",
       "25%      0.028645\n",
       "50%      0.031669\n",
       "75%      0.042094\n",
       "max      0.065571"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = pd.DataFrame(ae_train['loss'])\n",
    "loss.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.036263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.009051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.027208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.029038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.032269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.042447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.063496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  200.000000\n",
       "mean     0.036263\n",
       "std      0.009051\n",
       "min      0.027208\n",
       "25%      0.029038\n",
       "50%      0.032269\n",
       "75%      0.042447\n",
       "max      0.063496"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss = pd.DataFrame(ae_train['val_loss'])\n",
    "val_loss.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create encoded data\n",
    "encoded_data = encoder.predict(x_test)\n",
    "#decoded_data = decoder.predict(encoded_data)\n",
    "\n",
    "# transform to SOM input type\n",
    "encoded_som = pd.DataFrame(encoded_data)\n",
    "#decoded_som = pd.DataFrame(decoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5563663"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.664871</td>\n",
       "      <td>1.604236</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.820850</td>\n",
       "      <td>0.125911</td>\n",
       "      <td>1.076730</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.307412</td>\n",
       "      <td>3.301665</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.332330</td>\n",
       "      <td>2.137808</td>\n",
       "      <td>3.064919</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.424076</td>\n",
       "      <td>2.190599</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.661273</td>\n",
       "      <td>0.449278</td>\n",
       "      <td>1.538921</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.881969</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>2.855966</td>\n",
       "      <td>1.652026</td>\n",
       "      <td>0.310751</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.049503</td>\n",
       "      <td>1.354315</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.223567</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1    2    3    4    5         6         7         8    9   \\\n",
       "0  1.664871  1.604236 -0.0 -0.0 -0.0 -0.0  1.820850  0.125911  1.076730 -0.0   \n",
       "1  1.307412  3.301665 -0.0 -0.0 -0.0 -0.0  1.332330  2.137808  3.064919 -0.0   \n",
       "2  0.424076  2.190599 -0.0 -0.0 -0.0 -0.0  1.661273  0.449278  1.538921 -0.0   \n",
       "3  0.881969 -0.000000 -0.0 -0.0 -0.0 -0.0  2.855966  1.652026  0.310751 -0.0   \n",
       "4  0.049503  1.354315 -0.0 -0.0 -0.0 -0.0 -0.000000  0.223567 -0.000000 -0.0   \n",
       "\n",
       "    10   11  \n",
       "0 -0.0 -0.0  \n",
       "1 -0.0 -0.0  \n",
       "2 -0.0 -0.0  \n",
       "3 -0.0 -0.0  \n",
       "4 -0.0 -0.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_som.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>1.668378</td>\n",
       "      <td>1.617260</td>\n",
       "      <td>1.806663</td>\n",
       "      <td>0.155295</td>\n",
       "      <td>1.081879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.761137</td>\n",
       "      <td>3.487840</td>\n",
       "      <td>2.212331</td>\n",
       "      <td>1.849533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>2.477036</td>\n",
       "      <td>2.054956</td>\n",
       "      <td>0.555728</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.851163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.015561</td>\n",
       "      <td>1.352780</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.202852</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>2.656603</td>\n",
       "      <td>1.024365</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.166874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4\n",
       "405  1.668378  1.617260  1.806663  0.155295  1.081879\n",
       "406 -0.000000  1.761137  3.487840  2.212331  1.849533\n",
       "407  2.477036  2.054956  0.555728 -0.000000  0.851163\n",
       "408  0.015561  1.352780 -0.000000  0.202852 -0.000000\n",
       "409 -0.000000  2.656603  1.024365 -0.000000  1.166874"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonzero = list(map(lambda i: any(encoded_data[:,i] != 0), range(encoded_data.shape[1])))\n",
    "encoded_som_nonzero = pd.DataFrame(encoded_data[:,nonzero])\n",
    "encoded_som_nonzero.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_som_nonzero.to_csv(path_or_buf='output/dim064_SAE_encoded.csv',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contractive Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 614 samples, validate on 410 samples\n",
      "Epoch 1/200\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0639 - val_loss: 0.0619\n",
      "Epoch 2/200\n",
      "614/614 [==============================] - 0s 42us/step - loss: 0.0606 - val_loss: 0.0594\n",
      "Epoch 3/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0585 - val_loss: 0.0578\n",
      "Epoch 4/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0571 - val_loss: 0.0568\n",
      "Epoch 5/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0562 - val_loss: 0.0560\n",
      "Epoch 6/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0555 - val_loss: 0.0553\n",
      "Epoch 7/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0549 - val_loss: 0.0548\n",
      "Epoch 8/200\n",
      "614/614 [==============================] - 0s 32us/step - loss: 0.0543 - val_loss: 0.0542\n",
      "Epoch 9/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0537 - val_loss: 0.0536\n",
      "Epoch 10/200\n",
      "614/614 [==============================] - 0s 33us/step - loss: 0.0532 - val_loss: 0.0530\n",
      "Epoch 11/200\n",
      "614/614 [==============================] - 0s 40us/step - loss: 0.0526 - val_loss: 0.0524\n",
      "Epoch 12/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0520 - val_loss: 0.0519\n",
      "Epoch 13/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0514 - val_loss: 0.0513\n",
      "Epoch 14/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0509 - val_loss: 0.0507\n",
      "Epoch 15/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0504 - val_loss: 0.0502\n",
      "Epoch 16/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0498 - val_loss: 0.0497\n",
      "Epoch 17/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0493 - val_loss: 0.0491\n",
      "Epoch 18/200\n",
      "614/614 [==============================] - 0s 39us/step - loss: 0.0487 - val_loss: 0.0486\n",
      "Epoch 19/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0482 - val_loss: 0.0481\n",
      "Epoch 20/200\n",
      "614/614 [==============================] - 0s 39us/step - loss: 0.0477 - val_loss: 0.0476\n",
      "Epoch 21/200\n",
      "614/614 [==============================] - 0s 40us/step - loss: 0.0472 - val_loss: 0.0470\n",
      "Epoch 22/200\n",
      "614/614 [==============================] - 0s 40us/step - loss: 0.0467 - val_loss: 0.0466\n",
      "Epoch 23/200\n",
      "614/614 [==============================] - 0s 42us/step - loss: 0.0462 - val_loss: 0.0461\n",
      "Epoch 24/200\n",
      "614/614 [==============================] - 0s 41us/step - loss: 0.0457 - val_loss: 0.0456\n",
      "Epoch 25/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0452 - val_loss: 0.0451\n",
      "Epoch 26/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0448 - val_loss: 0.0446\n",
      "Epoch 27/200\n",
      "614/614 [==============================] - 0s 41us/step - loss: 0.0443 - val_loss: 0.0441\n",
      "Epoch 28/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0438 - val_loss: 0.0436\n",
      "Epoch 29/200\n",
      "614/614 [==============================] - 0s 40us/step - loss: 0.0433 - val_loss: 0.0432\n",
      "Epoch 30/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0429 - val_loss: 0.0427\n",
      "Epoch 31/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0424 - val_loss: 0.0422\n",
      "Epoch 32/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0419 - val_loss: 0.0417\n",
      "Epoch 33/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0414 - val_loss: 0.0413\n",
      "Epoch 34/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0410 - val_loss: 0.0408\n",
      "Epoch 35/200\n",
      "614/614 [==============================] - 0s 40us/step - loss: 0.0405 - val_loss: 0.0403\n",
      "Epoch 36/200\n",
      "614/614 [==============================] - 0s 40us/step - loss: 0.0400 - val_loss: 0.0398\n",
      "Epoch 37/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0396 - val_loss: 0.0394\n",
      "Epoch 38/200\n",
      "614/614 [==============================] - 0s 40us/step - loss: 0.0391 - val_loss: 0.0389\n",
      "Epoch 39/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0386 - val_loss: 0.0384\n",
      "Epoch 40/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0382 - val_loss: 0.0380\n",
      "Epoch 41/200\n",
      "614/614 [==============================] - 0s 39us/step - loss: 0.0377 - val_loss: 0.0375\n",
      "Epoch 42/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0373 - val_loss: 0.0371\n",
      "Epoch 43/200\n",
      "614/614 [==============================] - 0s 41us/step - loss: 0.0368 - val_loss: 0.0366\n",
      "Epoch 44/200\n",
      "614/614 [==============================] - 0s 41us/step - loss: 0.0363 - val_loss: 0.0362\n",
      "Epoch 45/200\n",
      "614/614 [==============================] - 0s 39us/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 46/200\n",
      "614/614 [==============================] - 0s 40us/step - loss: 0.0355 - val_loss: 0.0353\n",
      "Epoch 47/200\n",
      "614/614 [==============================] - 0s 39us/step - loss: 0.0350 - val_loss: 0.0349\n",
      "Epoch 48/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0346 - val_loss: 0.0345\n",
      "Epoch 49/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0342 - val_loss: 0.0340\n",
      "Epoch 50/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0337 - val_loss: 0.0336\n",
      "Epoch 51/200\n",
      "614/614 [==============================] - 0s 40us/step - loss: 0.0333 - val_loss: 0.0332\n",
      "Epoch 52/200\n",
      "614/614 [==============================] - 0s 40us/step - loss: 0.0329 - val_loss: 0.0328\n",
      "Epoch 53/200\n",
      "614/614 [==============================] - 0s 33us/step - loss: 0.0325 - val_loss: 0.0324\n",
      "Epoch 54/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0321 - val_loss: 0.0320\n",
      "Epoch 55/200\n",
      "614/614 [==============================] - 0s 33us/step - loss: 0.0317 - val_loss: 0.0316\n",
      "Epoch 56/200\n",
      "614/614 [==============================] - 0s 39us/step - loss: 0.0314 - val_loss: 0.0313\n",
      "Epoch 57/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0310 - val_loss: 0.0309\n",
      "Epoch 58/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0306 - val_loss: 0.0305\n",
      "Epoch 59/200\n",
      "614/614 [==============================] - 0s 40us/step - loss: 0.0303 - val_loss: 0.0302\n",
      "Epoch 60/200\n",
      "614/614 [==============================] - 0s 41us/step - loss: 0.0299 - val_loss: 0.0299\n",
      "Epoch 61/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0296 - val_loss: 0.0295\n",
      "Epoch 62/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0293 - val_loss: 0.0292\n",
      "Epoch 63/200\n",
      "614/614 [==============================] - 0s 48us/step - loss: 0.0289 - val_loss: 0.0289\n",
      "Epoch 64/200\n",
      "614/614 [==============================] - 0s 45us/step - loss: 0.0286 - val_loss: 0.0286\n",
      "Epoch 65/200\n",
      "614/614 [==============================] - 0s 40us/step - loss: 0.0283 - val_loss: 0.0282\n",
      "Epoch 66/200\n",
      "614/614 [==============================] - 0s 40us/step - loss: 0.0280 - val_loss: 0.0279\n",
      "Epoch 67/200\n",
      "614/614 [==============================] - 0s 39us/step - loss: 0.0277 - val_loss: 0.0277\n",
      "Epoch 68/200\n",
      "614/614 [==============================] - 0s 44us/step - loss: 0.0274 - val_loss: 0.0274\n",
      "Epoch 69/200\n",
      "614/614 [==============================] - 0s 39us/step - loss: 0.0272 - val_loss: 0.0271\n",
      "Epoch 70/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0269 - val_loss: 0.0268\n",
      "Epoch 71/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0266 - val_loss: 0.0265\n",
      "Epoch 72/200\n",
      "614/614 [==============================] - 0s 49us/step - loss: 0.0264 - val_loss: 0.0263\n",
      "Epoch 73/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0261 - val_loss: 0.0260\n",
      "Epoch 74/200\n",
      "614/614 [==============================] - 0s 40us/step - loss: 0.0259 - val_loss: 0.0258\n",
      "Epoch 75/200\n",
      "614/614 [==============================] - 0s 41us/step - loss: 0.0256 - val_loss: 0.0256\n",
      "Epoch 76/200\n",
      "614/614 [==============================] - 0s 41us/step - loss: 0.0254 - val_loss: 0.0253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/200\n",
      "614/614 [==============================] - 0s 41us/step - loss: 0.0252 - val_loss: 0.0251\n",
      "Epoch 78/200\n",
      "614/614 [==============================] - 0s 41us/step - loss: 0.0250 - val_loss: 0.0249\n",
      "Epoch 79/200\n",
      "614/614 [==============================] - 0s 41us/step - loss: 0.0247 - val_loss: 0.0246\n",
      "Epoch 80/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0245 - val_loss: 0.0244\n",
      "Epoch 81/200\n",
      "614/614 [==============================] - 0s 39us/step - loss: 0.0243 - val_loss: 0.0242\n",
      "Epoch 82/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0241 - val_loss: 0.0240\n",
      "Epoch 83/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0239 - val_loss: 0.0238\n",
      "Epoch 84/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0237 - val_loss: 0.0236\n",
      "Epoch 85/200\n",
      "614/614 [==============================] - 0s 39us/step - loss: 0.0235 - val_loss: 0.0234\n",
      "Epoch 86/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0234 - val_loss: 0.0232\n",
      "Epoch 87/200\n",
      "614/614 [==============================] - 0s 41us/step - loss: 0.0232 - val_loss: 0.0231\n",
      "Epoch 88/200\n",
      "614/614 [==============================] - 0s 40us/step - loss: 0.0230 - val_loss: 0.0229\n",
      "Epoch 89/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0228 - val_loss: 0.0227\n",
      "Epoch 90/200\n",
      "614/614 [==============================] - 0s 41us/step - loss: 0.0227 - val_loss: 0.0225\n",
      "Epoch 91/200\n",
      "614/614 [==============================] - 0s 39us/step - loss: 0.0225 - val_loss: 0.0224\n",
      "Epoch 92/200\n",
      "614/614 [==============================] - 0s 39us/step - loss: 0.0223 - val_loss: 0.0222\n",
      "Epoch 93/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0222 - val_loss: 0.0220\n",
      "Epoch 94/200\n",
      "614/614 [==============================] - 0s 40us/step - loss: 0.0220 - val_loss: 0.0219\n",
      "Epoch 95/200\n",
      "614/614 [==============================] - 0s 42us/step - loss: 0.0219 - val_loss: 0.0217\n",
      "Epoch 96/200\n",
      "614/614 [==============================] - 0s 40us/step - loss: 0.0217 - val_loss: 0.0216\n",
      "Epoch 97/200\n",
      "614/614 [==============================] - 0s 33us/step - loss: 0.0216 - val_loss: 0.0214\n",
      "Epoch 98/200\n",
      "614/614 [==============================] - 0s 42us/step - loss: 0.0214 - val_loss: 0.0213\n",
      "Epoch 99/200\n",
      "614/614 [==============================] - 0s 43us/step - loss: 0.0213 - val_loss: 0.0211\n",
      "Epoch 100/200\n",
      "614/614 [==============================] - 0s 41us/step - loss: 0.0212 - val_loss: 0.0210\n",
      "Epoch 101/200\n",
      "614/614 [==============================] - 0s 40us/step - loss: 0.0210 - val_loss: 0.0209\n",
      "Epoch 102/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0209 - val_loss: 0.0208\n",
      "Epoch 103/200\n",
      "614/614 [==============================] - 0s 45us/step - loss: 0.0208 - val_loss: 0.0206\n",
      "Epoch 104/200\n",
      "614/614 [==============================] - 0s 40us/step - loss: 0.0207 - val_loss: 0.0205\n",
      "Epoch 105/200\n",
      "614/614 [==============================] - 0s 39us/step - loss: 0.0205 - val_loss: 0.0204\n",
      "Epoch 106/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0204 - val_loss: 0.0203\n",
      "Epoch 107/200\n",
      "614/614 [==============================] - 0s 40us/step - loss: 0.0203 - val_loss: 0.0202\n",
      "Epoch 108/200\n",
      "614/614 [==============================] - 0s 39us/step - loss: 0.0202 - val_loss: 0.0200\n",
      "Epoch 109/200\n",
      "614/614 [==============================] - 0s 43us/step - loss: 0.0201 - val_loss: 0.0199\n",
      "Epoch 110/200\n",
      "614/614 [==============================] - 0s 40us/step - loss: 0.0200 - val_loss: 0.0198\n",
      "Epoch 111/200\n",
      "614/614 [==============================] - 0s 40us/step - loss: 0.0199 - val_loss: 0.0197\n",
      "Epoch 112/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0198 - val_loss: 0.0196\n",
      "Epoch 113/200\n",
      "614/614 [==============================] - 0s 39us/step - loss: 0.0197 - val_loss: 0.0195\n",
      "Epoch 114/200\n",
      "614/614 [==============================] - 0s 39us/step - loss: 0.0196 - val_loss: 0.0195\n",
      "Epoch 115/200\n",
      "614/614 [==============================] - 0s 39us/step - loss: 0.0195 - val_loss: 0.0194\n",
      "Epoch 116/200\n",
      "614/614 [==============================] - 0s 39us/step - loss: 0.0195 - val_loss: 0.0193\n",
      "Epoch 117/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0194 - val_loss: 0.0192\n",
      "Epoch 118/200\n",
      "614/614 [==============================] - 0s 41us/step - loss: 0.0193 - val_loss: 0.0191\n",
      "Epoch 119/200\n",
      "614/614 [==============================] - 0s 43us/step - loss: 0.0192 - val_loss: 0.0190\n",
      "Epoch 120/200\n",
      "614/614 [==============================] - 0s 40us/step - loss: 0.0191 - val_loss: 0.0190\n",
      "Epoch 121/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0191 - val_loss: 0.0189\n",
      "Epoch 122/200\n",
      "614/614 [==============================] - 0s 31us/step - loss: 0.0190 - val_loss: 0.0188\n",
      "Epoch 123/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0189 - val_loss: 0.0187\n",
      "Epoch 124/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0189 - val_loss: 0.0187\n",
      "Epoch 125/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0188 - val_loss: 0.0186\n",
      "Epoch 126/200\n",
      "614/614 [==============================] - 0s 40us/step - loss: 0.0187 - val_loss: 0.0185\n",
      "Epoch 127/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0187 - val_loss: 0.0185\n",
      "Epoch 128/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0186 - val_loss: 0.0184\n",
      "Epoch 129/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0185 - val_loss: 0.0184\n",
      "Epoch 130/200\n",
      "614/614 [==============================] - 0s 39us/step - loss: 0.0185 - val_loss: 0.0183\n",
      "Epoch 131/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0184 - val_loss: 0.0182\n",
      "Epoch 132/200\n",
      "614/614 [==============================] - 0s 41us/step - loss: 0.0184 - val_loss: 0.0182\n",
      "Epoch 133/200\n",
      "614/614 [==============================] - 0s 40us/step - loss: 0.0183 - val_loss: 0.0181\n",
      "Epoch 134/200\n",
      "614/614 [==============================] - 0s 40us/step - loss: 0.0183 - val_loss: 0.0181\n",
      "Epoch 135/200\n",
      "614/614 [==============================] - 0s 44us/step - loss: 0.0182 - val_loss: 0.0180\n",
      "Epoch 136/200\n",
      "614/614 [==============================] - 0s 40us/step - loss: 0.0182 - val_loss: 0.0180\n",
      "Epoch 137/200\n",
      "614/614 [==============================] - 0s 42us/step - loss: 0.0181 - val_loss: 0.0179\n",
      "Epoch 138/200\n",
      "614/614 [==============================] - 0s 41us/step - loss: 0.0180 - val_loss: 0.0179\n",
      "Epoch 139/200\n",
      "614/614 [==============================] - 0s 40us/step - loss: 0.0180 - val_loss: 0.0178\n",
      "Epoch 140/200\n",
      "614/614 [==============================] - 0s 42us/step - loss: 0.0180 - val_loss: 0.0178\n",
      "Epoch 141/200\n",
      "614/614 [==============================] - 0s 41us/step - loss: 0.0179 - val_loss: 0.0177\n",
      "Epoch 142/200\n",
      "614/614 [==============================] - 0s 40us/step - loss: 0.0179 - val_loss: 0.0177\n",
      "Epoch 143/200\n",
      "614/614 [==============================] - 0s 40us/step - loss: 0.0178 - val_loss: 0.0177\n",
      "Epoch 144/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0178 - val_loss: 0.0176\n",
      "Epoch 145/200\n",
      "614/614 [==============================] - 0s 39us/step - loss: 0.0177 - val_loss: 0.0176\n",
      "Epoch 146/200\n",
      "614/614 [==============================] - 0s 41us/step - loss: 0.0177 - val_loss: 0.0175\n",
      "Epoch 147/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0177 - val_loss: 0.0175\n",
      "Epoch 148/200\n",
      "614/614 [==============================] - 0s 40us/step - loss: 0.0176 - val_loss: 0.0174\n",
      "Epoch 149/200\n",
      "614/614 [==============================] - 0s 43us/step - loss: 0.0176 - val_loss: 0.0174\n",
      "Epoch 150/200\n",
      "614/614 [==============================] - 0s 40us/step - loss: 0.0175 - val_loss: 0.0174\n",
      "Epoch 151/200\n",
      "614/614 [==============================] - 0s 40us/step - loss: 0.0175 - val_loss: 0.0173\n",
      "Epoch 152/200\n",
      "614/614 [==============================] - 0s 39us/step - loss: 0.0175 - val_loss: 0.0173\n",
      "Epoch 153/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0174 - val_loss: 0.0173\n",
      "Epoch 154/200\n",
      "614/614 [==============================] - 0s 43us/step - loss: 0.0174 - val_loss: 0.0172\n",
      "Epoch 155/200\n",
      "614/614 [==============================] - 0s 41us/step - loss: 0.0173 - val_loss: 0.0172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156/200\n",
      "614/614 [==============================] - 0s 39us/step - loss: 0.0173 - val_loss: 0.0172\n",
      "Epoch 157/200\n",
      "614/614 [==============================] - 0s 40us/step - loss: 0.0173 - val_loss: 0.0171\n",
      "Epoch 158/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0172 - val_loss: 0.0171\n",
      "Epoch 159/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0172 - val_loss: 0.0171\n",
      "Epoch 160/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0172 - val_loss: 0.0170\n",
      "Epoch 161/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0171 - val_loss: 0.0170\n",
      "Epoch 162/200\n",
      "614/614 [==============================] - 0s 40us/step - loss: 0.0171 - val_loss: 0.0170\n",
      "Epoch 163/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0171 - val_loss: 0.0169\n",
      "Epoch 164/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0170 - val_loss: 0.0169\n",
      "Epoch 165/200\n",
      "614/614 [==============================] - 0s 40us/step - loss: 0.0170 - val_loss: 0.0169\n",
      "Epoch 166/200\n",
      "614/614 [==============================] - 0s 40us/step - loss: 0.0170 - val_loss: 0.0168\n",
      "Epoch 167/200\n",
      "614/614 [==============================] - 0s 41us/step - loss: 0.0169 - val_loss: 0.0168\n",
      "Epoch 168/200\n",
      "614/614 [==============================] - 0s 43us/step - loss: 0.0169 - val_loss: 0.0168\n",
      "Epoch 169/200\n",
      "614/614 [==============================] - 0s 42us/step - loss: 0.0169 - val_loss: 0.0168\n",
      "Epoch 170/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0168 - val_loss: 0.0167\n",
      "Epoch 171/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0168 - val_loss: 0.0167\n",
      "Epoch 172/200\n",
      "614/614 [==============================] - 0s 39us/step - loss: 0.0168 - val_loss: 0.0167\n",
      "Epoch 173/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0168 - val_loss: 0.0167\n",
      "Epoch 174/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0167 - val_loss: 0.0166\n",
      "Epoch 175/200\n",
      "614/614 [==============================] - 0s 41us/step - loss: 0.0167 - val_loss: 0.0166\n",
      "Epoch 176/200\n",
      "614/614 [==============================] - 0s 41us/step - loss: 0.0167 - val_loss: 0.0166\n",
      "Epoch 177/200\n",
      "614/614 [==============================] - 0s 42us/step - loss: 0.0166 - val_loss: 0.0165\n",
      "Epoch 178/200\n",
      "614/614 [==============================] - 0s 39us/step - loss: 0.0166 - val_loss: 0.0165\n",
      "Epoch 179/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0166 - val_loss: 0.0165\n",
      "Epoch 180/200\n",
      "614/614 [==============================] - 0s 42us/step - loss: 0.0166 - val_loss: 0.0165\n",
      "Epoch 181/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0165 - val_loss: 0.0164\n",
      "Epoch 182/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0165 - val_loss: 0.0164\n",
      "Epoch 183/200\n",
      "614/614 [==============================] - 0s 41us/step - loss: 0.0165 - val_loss: 0.0164\n",
      "Epoch 184/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0164 - val_loss: 0.0164\n",
      "Epoch 185/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0164 - val_loss: 0.0163\n",
      "Epoch 186/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0164 - val_loss: 0.0163\n",
      "Epoch 187/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0164 - val_loss: 0.0163\n",
      "Epoch 188/200\n",
      "614/614 [==============================] - 0s 40us/step - loss: 0.0163 - val_loss: 0.0163\n",
      "Epoch 189/200\n",
      "614/614 [==============================] - 0s 41us/step - loss: 0.0163 - val_loss: 0.0162\n",
      "Epoch 190/200\n",
      "614/614 [==============================] - 0s 40us/step - loss: 0.0163 - val_loss: 0.0162\n",
      "Epoch 191/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0163 - val_loss: 0.0162\n",
      "Epoch 192/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0162 - val_loss: 0.0162\n",
      "Epoch 193/200\n",
      "614/614 [==============================] - 0s 40us/step - loss: 0.0162 - val_loss: 0.0162\n",
      "Epoch 194/200\n",
      "614/614 [==============================] - 0s 41us/step - loss: 0.0162 - val_loss: 0.0161\n",
      "Epoch 195/200\n",
      "614/614 [==============================] - 0s 40us/step - loss: 0.0161 - val_loss: 0.0161\n",
      "Epoch 196/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0161 - val_loss: 0.0161\n",
      "Epoch 197/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0161 - val_loss: 0.0161\n",
      "Epoch 198/200\n",
      "614/614 [==============================] - 0s 41us/step - loss: 0.0161 - val_loss: 0.0160\n",
      "Epoch 199/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0160 - val_loss: 0.0160\n",
      "Epoch 200/200\n",
      "614/614 [==============================] - 0s 39us/step - loss: 0.0160 - val_loss: 0.0160\n"
     ]
    }
   ],
   "source": [
    "########### Contractive Autoencoder ##########\n",
    "input_dim = x_train.shape[1]\n",
    "input_layer = Input(shape=(input_dim, ))\n",
    "\n",
    "encoding_dim = 12\n",
    "#learning_rate = 1e-7\n",
    "\n",
    "encoded = Dense(encoding_dim, activation='relu', name = 'encoded')(input_layer)\n",
    "\n",
    "decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
    "\n",
    "# implenment an autoencoder, creat encoder and decoder\n",
    "\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "\n",
    "encoder = Model(input_layer, encoded)\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "\n",
    "lam = 10e-6\n",
    "\n",
    "def contractive_loss(y_pred, y_true):\n",
    "    \n",
    "        mse = K.mean(K.square(y_true - y_pred), axis=1)\n",
    "        W = K.variable(value=autoencoder.get_layer('encoded').get_weights()[0])\n",
    "        W = K.transpose(W)\n",
    "        h = autoencoder.get_layer('encoded').output\n",
    "        dh = h * (1 - h)\n",
    "        contractive = lam * K.sum(dh**2 * K.sum(W**2, axis=1), axis=1)\n",
    "\n",
    "        return mse + contractive\n",
    "    \n",
    "autoencoder.compile(optimizer='adam', loss= contractive_loss)\n",
    "ae_train = autoencoder.fit(x_train, x_train,\n",
    "                epochs=200,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test)\n",
    "                ).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd8VvX5//HXdWfvRcIKEBAZYUNEHKiIolgFUSoobi1Vq9bVfrHaam31p62rLhQrToYIolil2DrrQhIEFBEZBgkEQkISMghZ1++P+4AhBjLInXMnuZ6Px3nk3Od8zjlXTu7c7/tsUVWMMcaYw/G4XYAxxhj/Z2FhjDGmXhYWxhhj6mVhYYwxpl4WFsYYY+plYWGMMaZeFhbGuEREXhCRvzawbaaInHak8zGmqSwsTKsjIheJSLqIFItItogsFZETa7W5XERURKbUGn6KiFQ709bsjmvZ38KY1sXCwrQqInIL8ChwH9AR6A48BUys1fQyYDdwaR2z2a6qkbW6z31ZtzGtnYWFaTVEJAa4B/iNqr6uqiWqWqGqb6nq72q06wGcDEwHzhCRTkewzEwR+Z2IrBGREhF5TkQ6OlszRSLyXxGJq9F+goisFZECEflQRPrXGDdMRFY6070KhNZa1tkissqZ9jMRGdzEmn8lIhtFZLeILBGRLs5wEZFHRCRHRPaIyNciMtAZd5aIfOvUtk1EbmvSCjNtloWFaU2Ow/sBu7iedpcC6aq6CFgHTDvC5Z4PnA70Ac4BlgJ/ABLx/g/dCCAifYB5wE3OuHeAt0QkWESCgTeAl4F44DVnvjjTDgNmA78GEoBngCUiEtKYQkXkVOD/ARcAnYEtwHxn9DjgJOf3iHHa5DnjngN+rapRwEDg/cYs17R9FhamNUkAclW1sp52lwJznf65/HxXVBfn23vNLuIw83tcVXeq6jbgf8ByVf1KVcvwBtcwp90U4G1V/Y+qVgAPAmHA8cAoIAh41NkaWgisqLGM6cAzqrpcVatU9UVgnzNdY0wDZqvqSlXdB9wOHCciKUAFEAX0A0RV16lqtjNdBZAqItGqmq+qKxu5XNPGWViY1iQP6CAigYdqICInAD356dv0XGCQiAyt0Wy7qsbW6koOs9ydNfr31vE60unvgvebPACqWg1sBbo647bpwXfu3FKjvwdwa80AA7o50zVG7RqK8a63rqr6PvAE8CSQIyKzRCTaaXo+cBawRUQ+sgP+pjYLC9OafI732/a5h2lzGSDAKhHZASyvMdzXtuP90Ae8xwjwfuBvA7KBrs6w/brX6N8K3FsrwMJVdd4R1hCBd4tsG4CqPqaqI4BUvLujfucMX6GqE4EkvLvLFjRyuaaNs7AwrYaqFgJ/Ap4UkXNFJFxEgkRkvIj8TURC8e6Hnw4MrdHdAFx0uC2SZrIA+IWIjBWRIOBWvOH2Gd6gqwRudGo+DxhZY9pngWtE5FjnQHSEiPxCRKIaWcM84AoRGeoc77gP726zTBE5xpl/EFAClAHVzjGVaSIS4+w+2wNUH8F6MG2QhYVpVVT1IeAW4E5gF95v5Nfj/TZ8Lt7dQi+p6o79Hd4Dx4HAmc5sutRxncX5P1tY42tbD1wMPA7k4j0Yfo6qlqtqOXAecDneU3qnAK/XmDYd+BXe3UT5wEanbWNr+C/wR2AR3q2Zo4CpzuhovKGUj3dXVR7wd2fcJUCmiOwBruHITwowbYzYw4+MMcbUx7YsjDHG1MvCwhhjTL0sLIwxxtTLwsIYY0y9fH0qYYvp0KGDpqSkuF2GMca0KhkZGbmqmlhfuzYTFikpKaSnp7tdhjHGtCoisqX+VrYbyhhjTANYWBhjjKmXhYUxxph6tZljFsaYtqOiooKsrCzKysrcLqXNCA0NJTk5maCgoCZNb2FhjPE7WVlZREVFkZKSwsE36jVNoark5eWRlZVFz549mzQP2w1ljPE7ZWVlJCQkWFA0ExEhISHhiLbULCyMMX7JgqJ5Hen6bPdhsa1gLw+/u54teYd7UJoxxrRv7T4sCkrLeez9jazdvsftUowxfiIvL4+hQ4cydOhQOnXqRNeuXQ+8Li8vb9A8rrjiCtavX3/YNk8++SRz5sxpjpJ9rt0f4O4aGwbA9oK9LldijPEXCQkJrFq1CoC7776byMhIbrvttoPaqCqqisdT93fu559/vt7l/OY3vznyYltIu9+yiAkLIiwogO0FdoqeMebwNm7cSGpqKtOmTWPAgAFkZ2czffp00tLSGDBgAPfcc8+BtieeeCKrVq2isrKS2NhYZsyYwZAhQzjuuOPIyckB4M477+TRRx890H7GjBmMHDmSvn378tlnnwFQUlLC+eefT2pqKpMnTyYtLe1AkLWkdr9lISJ0jg0lu9C2LIzxR39+ay3fNvNu4tQu0dx1zoAmTfvdd9/x0ksvkZaWBsD9999PfHw8lZWVjBkzhsmTJ5OamnrQNIWFhZx88sncf//93HLLLcyePZsZM2b8bN6qypdffsmSJUu45557+Pe//83jjz9Op06dWLRoEatXr2b48OFNqvtItfstC/DuirLdUMaYhjjqqKMOBAXAvHnzGD58OMOHD2fdunV8++23P5smLCyM8ePHAzBixAgyMzPrnPd55533szaffPIJU6d6H6M+ZMgQBgxoWsgdqXa/ZQHQOSaU73YUuV2GMaYOTd0C8JWIiIgD/Rs2bOAf//gHX375JbGxsVx88cV1XssQHBx8oD8gIIDKyso65x0SElJvG7fYlgXQJTaMXUX72FdZ5XYpxphWZM+ePURFRREdHU12djbLli1r9mWccMIJLFiwAICvv/66zi2XlmBbFgU/ckb207wuA9lZuI/uCeFuV2SMaSWGDx9Oamoq/fr1o0ePHpxwwgnNvowbbriBSy+9lNTU1ANdTExMsy+nPqKqLb5QX0hLS9MmPfxo51qYeTzXl9/AxVffzKheCc1fnDGmUdatW0f//v3dLsMvVFZWUllZSWhoKBs2bGDcuHFs2LCBwMDGf9eva72KSIaqph1ikgNsyyK+FwA9JdsOchtj/E5xcTFjx46lsrISVeWZZ55pUlAcKQuLoDCqo5Ppmb+D7EK71sIY419iY2PJyMhwuww7wA3g6dCbPgHZbLMtC2OMqZOFBUBCb1JkB9n5pW5XYowxfsmnYSEiZ4rIehHZKCI/u1xRREJE5FVn/HIRSakxbrCIfC4ia0XkaxEJ9VmhCUcTqSUU797hs0UYY0xr5rOwEJEA4ElgPJAKXCgiqbWaXQXkq2pv4BHgAWfaQOAV4BpVHQCcAlT4qlYSegPgyd9EeWW1zxZjjDGtlS+3LEYCG1V1s6qWA/OBibXaTARedPoXAmPF+4SOccAaVV0NoKp5quq7K+YSjgKgO9n8kGvPtTCmvRszZszPLrB79NFHufbaaw85TWRkJADbt29n8uTJdbY55ZRTqO8U/0cffZTS0p92iZ911lkUFBQ0tHSf8WVYdAW21nid5Qyrs42qVgKFQALQB1ARWSYiK0Xk93UtQESmi0i6iKTv2rWr6ZXGdkc9QfSSbNbvtNt+GNPeXXjhhcyfP/+gYfPnz+fCCy+sd9ouXbqwcOHCJi+7dli88847xMbGNnl+zcVfD3AHAicC05yfk0RkbO1GqjpLVdNUNS0xMbHpS/MEoPE96eXZwfod9hAkY9q7yZMn8/bbbx940FFmZibbt29n2LBhjB07luHDhzNo0CDefPPNn02bmZnJwIEDAdi7dy9Tp06lf//+TJo0ib17fzrj8tprrz1wa/O77roLgMcee4zt27czZswYxowZA0BKSgq5ubkAPPzwwwwcOJCBAwceuLV5ZmYm/fv351e/+hUDBgxg3LhxBy2nufjyOottQLcar5OdYXW1yXKOU8QAeXi3Qj5W1VwAEXkHGA6856tiPR36kLr7K17bUeyrRRhjmmLpDNjxdfPOs9MgGH//IUfHx8czcuRIli5dysSJE5k/fz4XXHABYWFhLF68mOjoaHJzcxk1ahQTJkw45POtZ86cSXh4OOvWrWPNmjUH3V783nvvJT4+nqqqKsaOHcuaNWu48cYbefjhh/nggw/o0KHDQfPKyMjg+eefZ/ny5agqxx57LCeffDJxcXFs2LCBefPm8eyzz3LBBRewaNEiLr744uZZVw5fblmsAI4WkZ4iEgxMBZbUarMEuMzpnwy8r977jywDBolIuBMiJwO+vXtW1xF0q95G9o4sny7GGNM61NwVtX8XlKryhz/8gcGDB3Paaaexbds2du7cech5fPzxxwc+tAcPHszgwYMPjFuwYAHDhw9n2LBhrF27tt4bBH7yySdMmjSJiIgIIiMjOe+88/jf//4HQM+ePRk6dChw+FugHwmfbVmoaqWIXI/3gz8AmK2qa0XkHiBdVZcAzwEvi8hGYDfeQEFV80XkYbyBo8A7qvq2r2oFoPsoADoVrqFk39lEhNjF7cb4hcNsAfjSxIkTufnmm1m5ciWlpaWMGDGCF154gV27dpGRkUFQUBApKSl13pK8Pj/88AMPPvggK1asIC4ujssvv7xJ89lv/63NwXt7c1/shvLpMQtVfUdV+6jqUap6rzPsT05QoKplqvpLVe2tqiNVdXONaV9R1QGqOlBV6zzA3ay6DKNaghjh2cCGHNsVZUx7FxkZyZgxY7jyyisPHNguLCwkKSmJoKAgPvjgA7Zs2XLYeZx00knMnTsXgG+++YY1a9YA3lubR0REEBMTw86dO1m6dOmBaaKioigq+vmJNqNHj+aNN96gtLSUkpISFi9ezOjRo5vr162XfX3eLyiMiqRBjMj+njVZBQzt5v7ZB8YYd1144YVMmjTpwO6oadOmcc455zBo0CDS0tLo16/fYae/9tprueKKK+jfvz/9+/dnxIgRgPeJd8OGDaNfv35069btoFubT58+nTPPPJMuXbrwwQcfHBg+fPhwLr/8ckaOHAnA1VdfzbBhw3yyy6kudovyGvTft1P+xT+5qecSZl52XDNVZoxpLLtFuW8cyS3K/fXUWVdI91GEUM6ezelUVtmV3MYYs5+FRU3dj0fxMLJqJauzCt2uxhhj/IaFRU2RiVR2P5EJns/4dMMRXBFujDlibWUXub840vVpYVFL0JDJ9PTsIGvdF26XYky7FRoaSl5engVGM1FV8vLyCA1t+s277Wyo2vqfQ9W/buaoncvYunsy3eLD3a7ImHYnOTmZrKwsjuieb+YgoaGhJCcnN3l6C4vawuOpSBnDxM2fMmf5Jm4dP8jtioxpd4KCgujZs6fbZZgabDdUHUKP+zWdJJ+i9PlU2FlRxhhjYVGno0+nKKYvF1Us5t1vst2uxhhjXGdhURcRIsbcQh/PNtKXvUJVtR1kM8a0bxYWh+AZdD5FUUdxZfGzvJOxye1yjDHGVRYWhxIQRMSkf9DNs4uCZfdRVuG7p7oaY4y/s7A4DE+v0eT0msSUijeY+6//uF2OMca4xsKiHknn/Z3KgHAGfHU367PtkavGmPbJwqI+kYnoaXdzrGcdy+Y+Yge7jTHtkoVFA0SMupK8+GFcuucZFn2c4XY5xhjT4iwsGsLjIf7CWYRLObEf/IHtBc3/yEJjjPFnFhYNJIl9KD3+94yT5Sye85Td4MwY065YWDRC7NhbyI1K5YKcR1m64lu3yzHGmBZjYdEYAYHEXfgMcVJC9Tv/R17xPrcrMsaYFmFh0UgBXQZTOOIGzuZ/vDZvttvlGGNMi7CwaIKE8XeQG96LCVl/48PVG90uxxhjfM7CoikCg4mZMouOUkD+mzMoKqtwuyJjjPEpC4smCupxDHmDrmZS9X949bW5bpdjjDE+ZWFxBJLO+TO7Q5I5fcNfWbF+q9vlGGOMz1hYHIngcMJ/OZMenhwyF95ud6Y1xrRZFhZHKLT3SWT3uZjzy//FgsWvu12OMcb4hIVFM+h8/v0UBidx3Nq7WLtlp9vlGGNMs7OwaA4hUQSf+zhHyza+nncnFVXVbldkjDHNysKimUQMOIOsHucxee9CXn/7HbfLMcaYZmVh0YySpz5MSWAsgzLuYMP23W6XY4wxzcanYSEiZ4rIehHZKCIz6hgfIiKvOuOXi0iKMzxFRPaKyCqne9qXdTabsDj4xcOkSiZfvPwn2x1ljGkzfBYWIhIAPAmMB1KBC0UktVazq4B8Ve0NPAI8UGPcJlUd6nTX+KrO5hYzfBLZyeO5oHQec/71rtvlGGNMs/DllsVIYKOqblbVcmA+MLFWm4nAi07/QmCsiIgPa2oRnac+TkVgBIMz7mTVljy3yzHGmCPmy7DoCtS8rDnLGVZnG1WtBAqBBGdcTxH5SkQ+EpHRPqyz+UUm4jnrAYZ7NvDZnL+yt9wu1jPGtG7+eoA7G+iuqsOAW4C5IhJdu5GITBeRdBFJ37VrV4sXeTjhw6eyu+upXLHvFWYttt1RxpjWzZdhsQ3oVuN1sjOszjYiEgjEAHmquk9V8wBUNQPYBPSpvQBVnaWqaaqalpiY6INf4QiIED/lSQgM4aS1d/K/9dluV2SMMU3my7BYARwtIj1FJBiYCiyp1WYJcJnTPxl4X1VVRBKdA+SISC/gaGCzD2v1jeguBEx4hGGejXy74G4KS+1W5saY1slnYeEcg7geWAasAxao6loRuUdEJjjNngMSRGQj3t1N+0+vPQlYIyKr8B74vkZVW+WFC8FDfkn+URO5qnIB/3x1odvlGGNMk4iqul1Ds0hLS9P09HS3y6jb3gKKHhlJTpmH7yb+i1+M6O12RcYYA4CIZKhqWn3t/PUAd9sSFkv4BbM4ypNN0ZLb+TGv1O2KjDGmUSwsWkhA71MoGvZrpsq7PP/iLMor7epuY0zrYWHRgqLOuoei6KO5rvAhZv7rM7fLMcaYBrOwaElBoURNe4lYTxkjMn7Ph+vsdFpjTOtgYdHSOqbC+L9xYsBa1i74Mzl7ytyuyBhj6mVh4YKgYy6n6OiJXFM9n5kvvUxVdds4I80Y03ZZWLhBhKjzn6A0ohvTd93HC//101N+jTHGYWHhltBoIi9+iQ6eInp+8jsyMnPdrsgYYw7JwsJF0mUYlaf9hVM9X/HZK3+x24EYY/yWhYXLwo6/hoIeZ3BNxcs8NWc+beWKemNM22Jh4TYRYqc+Q1lYEpdk3c0rH65xuyJjjPkZCwt/EBZH5LSX6ST5dP7gZjIyW+U9E40xbZiFhZ+QbsdQceqfOc2Twacv383uknK3SzLGmAMsLPxI2OjrKUw5k2srX+GJl+ZQbddfGGP8hIWFPxEhZsoz7AvvxNU77uGf79r1F8YY/2Bh4W/CYom4eA5JniKO/vRWPvk+x+2KjDHGwsIfSddhVI+7lzEBq/lq3t3sKLT7Rxlj3GVh4aeCR02nqPcErquey5MvvEhFlT3/whjjHgsLfyVC1OQn2RvZnet338dTb9nzL4wx7rGw8Geh0UReMpc4z15GrbyVd7/e6nZFxph2ysLC33UaiEx4jGM937Fj4e/ZtKvY7YqMMe2QhUUrEDRsKsVDr+ZSeYf5sx+meF+l2yUZY9oZC4tWIvKc+9mTlMbNpU/wyCuL7YaDxpgWZWHRWgQEEX3JHDQkiku23MHz7612uyJjTDtiYdGaRHUi/OI5dPPk0uOjm+yCPWNMi7GwaGWk+ygqx93H2ICv+HreHWTll7pdkjGmHbCwaIVCjvs1RX0n82t9jX/Ofpqyiiq3SzLGtHEWFq2RCFHnP05JbF9u3vN3HlmwzA54G2N8ysKitQoOJ+rS+YQEBXLu+v9j3mfr3a7IGNOGWVi0ZvE9Cb5gNn09W4lYdgsZmXluV2SMaaMaFBYi8lsRiRav50RkpYiM83Vxpn6ePqdTfuIMJno+5YOX7iWnyO5Qa4xpfg3dsrhSVfcA44A44BLgfp9VZRol9NTfU9TjNH5b9QKPP/+S3aHWGNPsGhoW4vw8C3hZVdfWGGbc5vEQNfU59kV25Ya8e/nHG/9zuyJjTBvT0LDIEJF38YbFMhGJAur9+ioiZ4rIehHZKCIz6hgfIiKvOuOXi0hKrfHdRaRYRG5rYJ3tV1gskZe+SmxAGSevvo03Mja7XZExpg1paFhcBcwAjlHVUiAIuOJwE4hIAPAkMB5IBS4UkdQ65puvqr2BR4AHao1/GFjawBpNx1Q85z7JMZ7vKX5zBmu3F7pdkTGmjWhoWBwHrFfVAhG5GLgTqO+TaCSwUVU3q2o5MB+YWKvNROBFp38hMFZEBEBEzgV+ANY2sEYDBA6ezN4R13CxZxmLnn+IgtJyt0syxrQBDQ2LmUCpiAwBbgU2AS/VM01XoObTerKcYXW2UdVKvAGUICKRwP8Bfz7cAkRkuoiki0j6rl27GvirtH1hZ91LUadj+V35TB58aSFV1XbBnjHmyDQ0LCrVe4nwROAJVX0SiPJdWdwNPKKqh33Sj6rOUtU0VU1LTEz0YTmtTEAgURe/gobFMn37n5j5zgq3KzLGtHINDYsiEbkd7ymzb4uIB+9xi8PZBnSr8TrZGVZnGxEJBGKAPOBY4G8ikgncBPxBRK5vYK0GIDKJ8Glz6RKQz8Dlt7Hsm9qr3hhjGq6hYTEF2If3eosdeD/4/17PNCuAo0Wkp4gEA1OBJbXaLAEuc/onA++r12hVTVHVFOBR4D5VfaKBtZr9uh2DnvEApwSsZvNrf7RHshpjmqxBYeEExBwgRkTOBspU9bDHLJxjENcDy4B1wAJVXSsi94jIBKfZc3iPUWwEbsF7xpVpRkHHXkVp6lSulUU8P3umPZLVGNMk0pC7lYrIBXi3JD7EezHeaOB3qrrQp9U1Qlpamqanp7tdhn+q2EvxzLFo3mb+3v0Z/nzlBJyTzowx7ZyIZKhqWn3tGrob6g6811hcpqqX4j0t9o9HUqBpQUFhRF46n6DgEC7acgfPvv+N2xUZY1qZhoaFR1VrPsMzrxHTGn8Q252QKc/Tx7ONzh/exoff7XS7ImNMK9LQD/x/i8gyEblcRC4H3gbe8V1Zxhek96lUnnIH5wR8war5d9kBb2NMgzX0APfvgFnAYKebpar/58vCjG8En3wrpX0ncRPzeP65J9lTVuF2ScaYVqDBu5JUdZGq3uJ0i31ZlPEhEcInz6Q4YTC3732Iv724yK7wNsbU67BhISJFIrKnjq5IRPa0VJGmmQWFEXnZAiQ0hmu238Hj//rc7YqMMX7usGGhqlGqGl1HF6Wq0S1VpPGB6M6EXzqfjp49HJd+M29m/OB2RcYYP2ZnNLVnXUcgE5/gWM937HvzFtZszXe7ImOMn7KwaOcCh06h9NibuMDzPv994S/k7LFneBtjfs7CwhB+xl3s6TGO31bOZuZzz7KvssrtkowxfsbCwoDHQ/RFsymN6c3NBffxyLx3aMhtYIwx7YeFhfEKiSLqioUEBgUzZcOtzP6P3WfLGPMTCwvzk7gUwi59leSAfIZ8ch3vfGVnSBljvCwszEGk+yiY9DRpnu/Rxdeyckue2yUZY/yAhYX5maDB51N60h/5hedzVr1wK1t3l7pdkjHGZRYWpk7hY26lMHUaV+piXpv1Vwr32j2kjGnPLCxM3USIOf8x8juP5sa9M3l69iwqqqrdrsoY4xILC3NoAYHEXTaX4ujeXJfzF56a/4adUmtMO2VhYQ4vNJrYq9+A4Eh++f2tzF5qNx00pj2ysDD1i+lK5JWLiA/Yy7FfXMvrn3/ndkXGmBZmYWEaRDoPIXDKi/T3/EinpVfy4dof3S7JGNOCLCxMgwX2PYOKs5/geM9aKhdcyaotuW6XZIxpIRYWplFC06ZRNOavnCYr+PGFq9mcY8/AMqY9sLAwjRZ18g3sPuZWJugHrHjmOrbl20V7xrR1FhamSeLP+iO5A65gStVbLJt5G7nF+9wuyRjjQxYWpmlE6HD+w+QeNYkry+ew4Mk/2VXexrRhFham6TweOlz0LLldx3Ld3qd5eeZ9lJZXul2VMcYHLCzMkQkIosPlc8lNOp7rCh/hlZn3UVZhT9ozpq2xsDBHLiiUDr96nV2Jx3H17od5Zea9FhjGtDEWFqZ5BIXR8devszPpeK7e/RCvPPUXCwxj2hALC9N8gsLoPP11shNP5Or8R5jz1D0WGMa0ERYWpnkFhdJ5+iKyE0dzVf6jzH3qzxYYxrQBPg0LETlTRNaLyEYRmVHH+BARedUZv1xEUpzhI0VkldOtFpFJvqzTNLOgUDpPX8j2pNFcmf8P5j1xJ8X77CwpY1ozn4WFiAQATwLjgVTgQhFJrdXsKiBfVXsDjwAPOMO/AdJUdShwJvCMiAT6qlbjA0GhdJm+iOxOY7ii8CmW/ONGdtuFe8a0Wr7cshgJbFTVzapaDswHJtZqMxF40elfCIwVEVHVUlXd/1U0FLAn7rRGgSF0/tVCtqdM4qLSOXz8jyvYUWC3BjGmNfJlWHQFttZ4neUMq7ONEw6FQAKAiBwrImuBr4FraoTHASIyXUTSRSR9165dPvgVzBELCKTLpbPZnno151a8zZrHppC5s8DtqowxjeS3B7hVdbmqDgCOAW4XkdA62sxS1TRVTUtMTGz5Ik3DeDx0+eWDZB8zg3HVH7Pt6XP55odtbldljGkEX4bFNqBbjdfJzrA62zjHJGKAvJoNVHUdUAwM9FmlxvdE6PyL28k55e+M0tV4XjiLjzPWuF2VMaaBfBkWK4CjRaSniAQDU4EltdosAS5z+icD76uqOtMEAohID6AfkOnDWk0LSTplOkXnvUKKZye9l0xkybvvul2SMaYBfBYWzjGG64FlwDpggaquFZF7RGSC0+w5IEFENgK3APtPrz0RWC0iq4DFwHWqao9layNiB/8CufLfhAZ6OPXTS5g75zmqq+0cBmP8mai2jX/StLQ0TU9Pd7sM0whVBdvIeWYiiaWbeLXD9UycfheRIXaGtDEtSUQyVDWtvnZ+e4DbtH0BsV3p9Nv3yU48gWl5j/Hhg9PI3JnvdlnGmDpYWBhXSWg03a57k6wB13B2xb/JmzmeT1evc7ssY0wtFhbGfZ4Akn/5AHlnPMVANpHy+tkseOsd2souUmPaAgsL4zcSjptG9RVLCQ8Szkm/jNlP3U9hqT2q1Rh/YGFh/EpYjzRif/sJBXGDuGrX/Xz80FQ+i3D5AAASpUlEQVTW/LDD7bKMafcsLIzfkahOdL7hXbKHXM85Vf8l6IXTef3dD223lDEusrAw/ikgkM6T7qV48nySAwoY9+kUnpv5d/LszrXGuMLCwvi1yIHjifzt5xTH9uPqnHv58qHz+XDVBrfLMqbdsbAwfk9ikul043vsOuZWxumn9Fk8jlkvPE9RmR38NqalWFiY1iEgkMRf/InqK/9DSFgU0zNv4u0Hr2T5hu1uV2ZMu2BhYVqVoO5pJNzyBTn9LmFq5RISXz6VF+bNo7TcHttqjC9ZWJjWJzicpKlPUHbhQuJC4fL117D0gYv5+JvNbldmTJtlYWFardC+pxN3azo7+l/BpKp/c9Rrp/HUszPJKSpzuzRj2hwLC9O6hUTSacqjVF6+lLDwaK7bNoOVD53Lax8sp7Kq2u3qjGkzLCxMmxCcchzxty5n98jbOJV0zvxwIrP+9js+/i7b7dKMaRMsLEzbERhC/Fl/JOiGLynrnMZ1+/5JwtwzuO/pF9m0q9jt6oxp1SwsTJsjCb1I/PVbVJz/PD3C9vKHHTey7rHJPLboPbsxoTFNZGFh2iYRggadR+QtX1Ey6hbGBa7k12umsPBvv2LeJ99SYcczjGkUe6yqaR8Ksyh4605iNy5ml8YwL+SX9Bh3HWcP70WAR9yuzhjX2GNVjakpJpnYi19Ar36PwI79uLH8n4x86zSe+NsMlq7eQnV12/jSZIyvWFiYdkWS04i77l2qL3mTkA49+G3Z0wx6/VQee/BPvL82y26Dbswh2G4o036pUrXhPQrfuYv4gm/IrO7IoqiL6DvuKsYPSrbdU6ZdaOhuKAsLY1Sp/G4pRUvvIW7POjZVd2ZO2EX0PfUSzh3RnZDAALcrNMZnLCyMaSxVqr5dQumyvxC1ZwObqzvxatC5dBp9OZNH9SYqNMjtCo1pdhYWxjRVdTW6bgnF7z1I1O6v2aUxzOEsyoZczgWjB9IrMdLtCo1pNhYWxhwpVfjhY/a89xDR2z6iWMOYU3Uq33W/iAknjeTkPol47LiGaeUsLIxpTtlrKPvoEYK/exNF+W/VcJZFnMPAEyYw+ZhuRNsuKtNKWVgY4wsFP1L15XNUpr9ISHk+G6u7MJ9xlPafwjkj+3Jsz3jb2jCtioWFMb5UUQbfvkHpJzMJ37WKUg3hzarj+V/E6fRNO53zRiTTLT7c7SqNqZeFhTEtZdtKKpc/C2sXE1i1lx+qO7Ko6iR+TD6HMaNGcMaAToQHB7pdpTF1srAwpqXtK4Z1SyhLf4XQrE8B+LRqAG/JyZT3OZtxQ3txSt8kQoPsug3jPywsjHFT/haqV8+nPP0VQot/pJRQ3qsayvsyioC+Z3D60F6c3CfRgsO4zi/CQkTOBP4BBAD/VNX7a40PAV4CRgB5wBRVzRSR04H7gWCgHPidqr5/uGVZWBi/pAo/fkH16vlUrl1C8L7d7CWYj6qG8J6MYl+v0zlhQE/G9E0iKTrU7WpNO+R6WIhIAPA9cDqQBawALlTVb2u0uQ4YrKrXiMhUYJKqThGRYcBOVd0uIgOBZara9XDLs7Awfq+6Cn78nKq1b1D5zZuE7M2hnEA+rhrEsupjyOk4mmGp/Titf0cGdIlGxM6qMr7nD2FxHHC3qp7hvL4dQFX/X402y5w2n4tIILADSNQaRYn3PyYP6Kyq+w61PAsL06pUV0PWCvRbb3AEFW8D4JvqFD6oHsrq0GOI63M8xx+dxAlHdbCtDuMzDQ0LX56i0RXYWuN1FnDsodqoaqWIFAIJQG6NNucDK+sKChGZDkwH6N69e/NVboyveTzQ/Vik+7EEnXEf7PwGNvyHvuuXkbrtLTyVb1D4bQQffT2Y+6uGsD3+WPr16csJvTswMiWemHC7CNC0LL8+n09EBgAPAOPqGq+qs4BZ4N2yaMHSjGk+ItBpEHQaRNDoW2BvPmz6gOgN7zL++/8yYe/nUPw0mRmd+OLLfvy5uh8749NITunLiB5xDO8RR68OEXYxoPEpX4bFNqBbjdfJzrC62mQ5u6Fi8O5yQkSSgcXApaq6yYd1GuNfwuJg4HnIwPMIqq6GHash8xO6ZX5KcuZnTC3/EIph2zeJfLG6H7Oq+/Ft0CASu/djREo8w7vHMaRbLBEhfv1d0LQyvjxmEYj3APdYvKGwArhIVdfWaPMbYFCNA9znqeoFIhILfAT8WVVfb8jy7JiFaReqqyHnW9jyKZr5CVWZnxK4Nw+AfIkho7IXa6qP4mt6sbfDEFK6d2dA1xgGdommf+doO1XX/IzrB7idIs4CHsV76uxsVb1XRO4B0lV1iYiEAi8Dw4DdwFRV3SwidwK3AxtqzG6cquYcalkWFqZdUoXc7yHzE9iWQdXWdDx53yN4/6+zSOKrql6srj6K9fSgIr4fXbp2p2/naHonRXJ0UhTJcWG2C6sd84uwaEkWFsY49hXB9lWwfSW6LYOqrRkEFmUdGJ1PNN9VJfOdduN7TeYHTw8qEvqR3CmJo5Mi6Z0USe+kKHokhBMU4HHxFzEtwcLCGPOTklzYuRZy1kHOWip3fIvkrCOgsuRAk2wSWVuVzPfaje+qu7FFukJ8L7p2SqJ3UhS9kyJJSQinR3yEnY3VhlhYGGMOr7oaCrd6j4E4QVK9cy2SuwHRygPNdhPD5uqO/FDdiUz1drnByRDfk8QOHejhBEj3hHB6JITTMSrUdmu1IhYWxpimqSyHvI3ebvcmyNtEdd4mqnI3EVS686Cm+cSwtTqBrdqBbZpIlnZgpySyL7IrEtuduPgOJMeG0SU2jK5xzs/YMDvQ7kf84aI8Y0xrFBgMHVO9ncPjdJSXwO7NkLcJdm8iLn8LMQVb6b97C56i1QRUOdfOlgE7YM+OCLKqO5ClHdioHfjQCZXS0I4ExHQhLK4zSbGRdIwOpWN0yIGfSdGhRIUE2i1P/IiFhTGm4YIjDlxAuN+BIFGFkl1QsBUKtkDhVqILttKv4EeO3r0Fz571BFQUeyeqBvKhOl/I0xh2aCw7NY4tGsdyjWcncRR4EqiM6AjRnYmITSIpOoyO0aEkHQiVUJKiQux6khZia9kY0zxEIDLJ2yWPODD4oDApK4CCH2FPNhRl4ynaQWLRduIKs+lTuB1P8WqCyvJ+mmeZt6vICSRHY8nVaHZrFFnEsFqj2K3RlATGUR2eABEdCIhMIjg6kajoGBIiQ0iICCY+IpgOkcHER4QQGxZkx1OayMLCGNMyRLxXp4fFQechB40KpMaHUWU5FO+Aoh1QlA17sgkqyqZLUTYdi3ZRWbwLKdlAYFkeAdXl3mn2Op1zV7lSDWE3UeRpNHkazSqiydVo8oliX3A8FaEJEN4BT1QiwdFJREfFEB8ZTEKE01m4/IyFhTHGvwQGQ2x3b1eDUCtUVKG82HtacEkulDo/S3YRUpJLQmEOsUU5HFWai2fv9wTv201gdbl3F1ip09UIl3wiKdRI8jWS9URQoFEUSiT7gmKoDolDw+LwRMQTFJlAaFQHwmM7EB8VQXyNcIkJCyKgjYaLhYUxpnUSgZAobxff86BRAUBY7fYHwmUXlOQ54bILSnIJKcklviiP6KJcuu7Nx7M3l8DyjQRXFBJQXfXTlsvug2dZoiEUEkGhRrCBCAo0ktKASMoDo6kIjqEqJAYNjcMTHktgRDzBEfGERscTEZNAdEQ4ceFBxIYHEx0aSKCfXwBpYWGMaR8OCpdeB42qM1zAGzD7imDvbu/dgEu9PytL8ijbk8e+ot0ElOwmtjSf2LJCepUXEFKxhZDKIkJKy7xbL4dQoiEUEU6uhvMD4ZR6ItkXEEFFUDSVQVFoSDSExhAQFkNgRBzBEbGERcUTHh1PZGwCMVHRxIQHt1jIWFgYY8yhiEBotLeLSzkwOBCIdLpDqtwHZYXekNlbQFVpPmVFeZTtyaW8pICKkgJ0bwHBZXtI3FdIQEURwRU5hJSXEFZWTFBR5eHmToUGsIcwiolgS9IYRv/mmWb4hQ/NwsIYY3whMOSns8Pwbr1EOF29VKGyDMoKqS4toLQon5I9eZQV5VNWvJvK0kKqSgvQsj1IWSERHXz/8DcLC2OM8TciEBQGQWF4ojoR2bGerZgW4N9HVIwxxvgFCwtjjDH1srAwxhhTLwsLY4wx9bKwMMYYUy8LC2OMMfWysDDGGFMvCwtjjDH1ajOPVRWRXcCWI5hFBw7cg9KvWF2NY3U1nr/WZnU1TlPr6qGqifU1ajNhcaREJL0hz6FtaVZX41hdjeevtVldjePrumw3lDHGmHpZWBhjjKmXhcVPZrldwCFYXY1jdTWev9ZmdTWOT+uyYxbGGGPqZVsWxhhj6mVhYYwxpl7tPixE5EwRWS8iG0Vkhot1dBORD0TkWxFZKyK/dYbfLSLbRGSV053lUn2ZIvK1U0O6MyxeRP4jIhucn3EtXFPfGutllYjsEZGb3FhnIjJbRHJE5Jsaw+pcP+L1mPOeWyMiw1u4rr+LyHfOsheLSKwzPEVE9tZYb0/7qq7D1HbIv52I3O6ss/UickYL1/VqjZoyRWSVM7zF1tlhPiNa5n2mqu22w/ukw01ALyAYWA2kulRLZ2C40x8FfA+kAncDt/nBusoEOtQa9jdghtM/A3jA5b/lDqCHG+sMOAkYDnxT3/oBzgKWAgKMApa3cF3jgECn/4EadaXUbOfSOqvzb+f8L6wGQoCezv9tQEvVVWv8Q8CfWnqdHeYzokXeZ+19y2IksFFVN6tqOTAfmOhGIaqaraornf4iYB3Q1Y1aGmEi8KLT/yJwrou1jAU2qeqRXMXfZKr6MbC71uBDrZ+JwEvq9QUQKyKdW6ouVX1XVSudl18Ayb5Ydn0Osc4OZSIwX1X3qeoPwEa8/78tWpeICHABMM8Xyz6cw3xGtMj7rL2HRVdga43XWfjBB7SIpADDgOXOoOudzcjZLb2rpwYF3hWRDBGZ7gzrqKrZTv8OoKM7pQEwlYP/gf1hnR1q/fjT++5KvN8+9+spIl+JyEciMtqlmur62/nLOhsN7FTVDTWGtfg6q/UZ0SLvs/YeFn5HRCKBRcBNqroHmAkcBQwFsvFuArvhRFUdDowHfiMiJ9Ucqd7tXlfOwxaRYGAC8JozyF/W2QFurp9DEZE7gEpgjjMoG+iuqsOAW4C5IhLdwmX53d+ulgs5+EtJi6+zOj4jDvDl+6y9h8U2oFuN18nOMFeISBDeN8EcVX0dQFV3qmqVqlYDz+KjTe/6qOo252cOsNipY+f+zVrnZ44bteENsJWqutOp0S/WGYdeP66/70TkcuBsYJrzAYOziyfP6c/Ae1ygT0vWdZi/nT+ss0DgPODV/cNaep3V9RlBC73P2ntYrACOFpGezrfTqcASNwpx9oU+B6xT1YdrDK+5j3ES8E3taVugtggRidrfj/cA6Td419VlTrPLgDdbujbHQd/2/GGdOQ61fpYAlzpnq4wCCmvsRvA5ETkT+D0wQVVLawxPFJEAp78XcDSwuaXqcpZ7qL/dEmCqiISISE+nti9bsjbgNOA7Vc3aP6Al19mhPiNoqfdZSxzF9+cO7xkD3+P9RnCHi3WciHfzcQ2wyunOAl4GvnaGLwE6u1BbL7xnoqwG1u5fT0AC8B6wAfgvEO9CbRFAHhBTY1iLrzO8YZUNVODdN3zVodYP3rNTnnTec18DaS1c10a8+7L3v8+edtqe7/x9VwErgXNcWGeH/NsBdzjrbD0wviXrcoa/AFxTq22LrbPDfEa0yPvMbvdhjDGmXu19N5QxxpgGsLAwxhhTLwsLY4wx9bKwMMYYUy8LC2OMMfWysDDGD4jIKSLyL7frMOZQLCyMMcbUy8LCmEYQkYtF5Evn2QXPiEiAiBSLyCPOMwbeE5FEp+1QEflCfnpuxP7nDPQWkf+KyGoRWSkiRzmzjxSRheJ91sQc54pdY/yChYUxDSQi/YEpwAmqOhSoAqbhvYo8XVUHAB8BdzmTvAT8n6oOxnsF7f7hc4AnVXUIcDzeq4XBexfRm/A+o6AXcILPfyljGijQ7QKMaUXGAiOAFc6X/jC8N22r5qeby70CvC4iMUCsqn7kDH8ReM25x1ZXVV0MoKplAM78vlTnvkPifRJbCvCJ738tY+pnYWFMwwnwoqreftBAkT/WatfUe+jsq9Ffhf1/Gj9iu6GMabj3gMkikgQHnn3cA+//0WSnzUXAJ6paCOTXeBjOJcBH6n3CWZaInOvMI0REwlv0tzCmCeybizENpKrfisideJ8Y6MF7V9LfACXASGdcDt7jGuC9XfTTThhsBq5whl8CPCMi9zjz+GUL/hrGNIndddaYIyQixaoa6XYdxviS7YYyxhhTL9uyMMYYUy/bsjDGGFMvCwtjjDH1srAwxhhTLwsLY4wx9bKwMMYYU6//D9HVj9BpfC90AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CAE loss\n",
    "plt.plot(ae_train['loss'])\n",
    "plt.plot(ae_train['val_loss'])\n",
    "plt.title('CAE model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.026834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.012162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.016024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.017521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.021098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.033431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.063864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  200.000000\n",
       "mean     0.026834\n",
       "std      0.012162\n",
       "min      0.016024\n",
       "25%      0.017521\n",
       "50%      0.021098\n",
       "75%      0.033431\n",
       "max      0.063864"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = pd.DataFrame(ae_train['loss'])\n",
    "loss.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.026681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.012098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.016006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.017361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.020940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.033300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.061931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  200.000000\n",
       "mean     0.026681\n",
       "std      0.012098\n",
       "min      0.016006\n",
       "25%      0.017361\n",
       "50%      0.020940\n",
       "75%      0.033300\n",
       "max      0.061931"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss = pd.DataFrame(ae_train['val_loss'])\n",
    "val_loss.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create encoded data\n",
    "encoded_data = encoder.predict(x_test)\n",
    "#decoded_data = decoder.predict(encoded_data)\n",
    "\n",
    "# transform to SOM input type\n",
    "encoded_som = pd.DataFrame(encoded_data)\n",
    "#decoded_som = pd.DataFrame(decoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.758724"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.132602</td>\n",
       "      <td>0.194167</td>\n",
       "      <td>1.657366</td>\n",
       "      <td>2.710675</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>2.290873</td>\n",
       "      <td>1.387486</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.273360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.205261</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.358912</td>\n",
       "      <td>2.794274</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.713635</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.988429</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.828771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.822687</td>\n",
       "      <td>1.849295</td>\n",
       "      <td>1.304578</td>\n",
       "      <td>1.202002</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.006992</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>2.366884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.332502</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.091135</td>\n",
       "      <td>0.888521</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>2.753647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.893103</td>\n",
       "      <td>1.129324</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.983290</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>2.293613</td>\n",
       "      <td>2.785163</td>\n",
       "      <td>1.220750</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>2.000231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3    4    5    6         7         8   \\\n",
       "0  0.132602  0.194167  1.657366  2.710675 -0.0 -0.0 -0.0 -0.000000  2.290873   \n",
       "1  2.205261 -0.000000  1.358912  2.794274 -0.0 -0.0 -0.0  0.713635 -0.000000   \n",
       "2  0.822687  1.849295  1.304578  1.202002 -0.0 -0.0 -0.0 -0.000000 -0.000000   \n",
       "3 -0.000000 -0.000000  1.332502 -0.000000 -0.0 -0.0 -0.0 -0.000000  1.091135   \n",
       "4  0.893103  1.129324 -0.000000  1.983290 -0.0 -0.0 -0.0  2.293613  2.785163   \n",
       "\n",
       "         9    10        11  \n",
       "0  1.387486 -0.0  1.273360  \n",
       "1  0.988429 -0.0  0.828771  \n",
       "2  0.006992 -0.0  2.366884  \n",
       "3  0.888521 -0.0  2.753647  \n",
       "4  1.220750 -0.0  2.000231  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_som.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>0.141181</td>\n",
       "      <td>0.178557</td>\n",
       "      <td>1.647035</td>\n",
       "      <td>2.695401</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>2.267053</td>\n",
       "      <td>1.390108</td>\n",
       "      <td>1.261057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>0.515937</td>\n",
       "      <td>0.503931</td>\n",
       "      <td>0.797596</td>\n",
       "      <td>1.616801</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>2.668694</td>\n",
       "      <td>2.766420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>0.112266</td>\n",
       "      <td>1.331057</td>\n",
       "      <td>1.710154</td>\n",
       "      <td>1.976139</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.681474</td>\n",
       "      <td>0.283597</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.900244</td>\n",
       "      <td>1.141552</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>2.008343</td>\n",
       "      <td>2.304365</td>\n",
       "      <td>2.814506</td>\n",
       "      <td>1.248465</td>\n",
       "      <td>2.030923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>1.569984</td>\n",
       "      <td>3.347661</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.894827</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.456848</td>\n",
       "      <td>1.632554</td>\n",
       "      <td>1.713374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "405  0.141181  0.178557  1.647035  2.695401 -0.000000  2.267053  1.390108   \n",
       "406  0.515937  0.503931  0.797596  1.616801 -0.000000 -0.000000  2.668694   \n",
       "407  0.112266  1.331057  1.710154  1.976139 -0.000000  1.681474  0.283597   \n",
       "408  0.900244  1.141552 -0.000000  2.008343  2.304365  2.814506  1.248465   \n",
       "409  1.569984  3.347661 -0.000000  1.894827 -0.000000  0.456848  1.632554   \n",
       "\n",
       "            7  \n",
       "405  1.261057  \n",
       "406  2.766420  \n",
       "407 -0.000000  \n",
       "408  2.030923  \n",
       "409  1.713374  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonzero = list(map(lambda i: any(encoded_data[:,i] != 0), range(encoded_data.shape[1])))\n",
    "\n",
    "encoded_som_nonzero = pd.DataFrame(encoded_data[:,nonzero])\n",
    "\n",
    "encoded_som_nonzero.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_som_nonzero.to_csv(path_or_buf='output/dim064_CAE_encoded.csv',index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Denoising Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 614 samples, validate on 410 samples\n",
      "Epoch 1/200\n",
      "614/614 [==============================] - 1s 1ms/step - loss: 0.0626 - val_loss: 0.0613\n",
      "Epoch 2/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0604 - val_loss: 0.0597\n",
      "Epoch 3/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0590 - val_loss: 0.0587\n",
      "Epoch 4/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0582 - val_loss: 0.0581\n",
      "Epoch 5/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0576 - val_loss: 0.0576\n",
      "Epoch 6/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0572 - val_loss: 0.0573\n",
      "Epoch 7/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0569 - val_loss: 0.0570\n",
      "Epoch 8/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0566 - val_loss: 0.0567\n",
      "Epoch 9/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0562 - val_loss: 0.0564\n",
      "Epoch 10/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0559 - val_loss: 0.0561\n",
      "Epoch 11/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0556 - val_loss: 0.0558\n",
      "Epoch 12/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0552 - val_loss: 0.0555\n",
      "Epoch 13/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0549 - val_loss: 0.0551\n",
      "Epoch 14/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0545 - val_loss: 0.0548\n",
      "Epoch 15/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0542 - val_loss: 0.0544\n",
      "Epoch 16/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0538 - val_loss: 0.0541\n",
      "Epoch 17/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0534 - val_loss: 0.0537\n",
      "Epoch 18/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0530 - val_loss: 0.0534\n",
      "Epoch 19/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0526 - val_loss: 0.0530\n",
      "Epoch 20/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0523 - val_loss: 0.0527\n",
      "Epoch 21/200\n",
      "614/614 [==============================] - 0s 39us/step - loss: 0.0519 - val_loss: 0.0523\n",
      "Epoch 22/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0515 - val_loss: 0.0520\n",
      "Epoch 23/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0512 - val_loss: 0.0517\n",
      "Epoch 24/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0508 - val_loss: 0.0513\n",
      "Epoch 25/200\n",
      "614/614 [==============================] - 0s 25us/step - loss: 0.0505 - val_loss: 0.0510\n",
      "Epoch 26/200\n",
      "614/614 [==============================] - 0s 29us/step - loss: 0.0502 - val_loss: 0.0508\n",
      "Epoch 27/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0499 - val_loss: 0.0505\n",
      "Epoch 28/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0496 - val_loss: 0.0502\n",
      "Epoch 29/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0493 - val_loss: 0.0500\n",
      "Epoch 30/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0490 - val_loss: 0.0497\n",
      "Epoch 31/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0488 - val_loss: 0.0495\n",
      "Epoch 32/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0485 - val_loss: 0.0492\n",
      "Epoch 33/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0482 - val_loss: 0.0490\n",
      "Epoch 34/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0480 - val_loss: 0.0488\n",
      "Epoch 35/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0477 - val_loss: 0.0486\n",
      "Epoch 36/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0474 - val_loss: 0.0483\n",
      "Epoch 37/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0471 - val_loss: 0.0481\n",
      "Epoch 38/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0469 - val_loss: 0.0479\n",
      "Epoch 39/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0466 - val_loss: 0.0477\n",
      "Epoch 40/200\n",
      "614/614 [==============================] - 0s 39us/step - loss: 0.0463 - val_loss: 0.0474\n",
      "Epoch 41/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0460 - val_loss: 0.0472\n",
      "Epoch 42/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0457 - val_loss: 0.0470\n",
      "Epoch 43/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0455 - val_loss: 0.0467\n",
      "Epoch 44/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0452 - val_loss: 0.0465\n",
      "Epoch 45/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0449 - val_loss: 0.0462\n",
      "Epoch 46/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0446 - val_loss: 0.0460\n",
      "Epoch 47/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0443 - val_loss: 0.0457\n",
      "Epoch 48/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0440 - val_loss: 0.0455\n",
      "Epoch 49/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0437 - val_loss: 0.0452\n",
      "Epoch 50/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0434 - val_loss: 0.0450\n",
      "Epoch 51/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0431 - val_loss: 0.0447\n",
      "Epoch 52/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0428 - val_loss: 0.0445\n",
      "Epoch 53/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0425 - val_loss: 0.0442\n",
      "Epoch 54/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0422 - val_loss: 0.0439\n",
      "Epoch 55/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0419 - val_loss: 0.0437\n",
      "Epoch 56/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0416 - val_loss: 0.0434\n",
      "Epoch 57/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0413 - val_loss: 0.0432\n",
      "Epoch 58/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0410 - val_loss: 0.0429\n",
      "Epoch 59/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0407 - val_loss: 0.0426\n",
      "Epoch 60/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0404 - val_loss: 0.0424\n",
      "Epoch 61/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0401 - val_loss: 0.0421\n",
      "Epoch 62/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0398 - val_loss: 0.0419\n",
      "Epoch 63/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0396 - val_loss: 0.0416\n",
      "Epoch 64/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0393 - val_loss: 0.0414\n",
      "Epoch 65/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0390 - val_loss: 0.0411\n",
      "Epoch 66/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0388 - val_loss: 0.0409\n",
      "Epoch 67/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0385 - val_loss: 0.0406\n",
      "Epoch 68/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0383 - val_loss: 0.0404\n",
      "Epoch 69/200\n",
      "614/614 [==============================] - 0s 25us/step - loss: 0.0380 - val_loss: 0.0402\n",
      "Epoch 70/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0378 - val_loss: 0.0399\n",
      "Epoch 71/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0376 - val_loss: 0.0397\n",
      "Epoch 72/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0373 - val_loss: 0.0395\n",
      "Epoch 73/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0371 - val_loss: 0.0392\n",
      "Epoch 74/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0368 - val_loss: 0.0390\n",
      "Epoch 75/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0366 - val_loss: 0.0387\n",
      "Epoch 76/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0363 - val_loss: 0.0384\n",
      "Epoch 77/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0361 - val_loss: 0.0382\n",
      "Epoch 78/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0358 - val_loss: 0.0379\n",
      "Epoch 79/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0356 - val_loss: 0.0376\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614/614 [==============================] - 0s 37us/step - loss: 0.0353 - val_loss: 0.0374\n",
      "Epoch 81/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0350 - val_loss: 0.0371\n",
      "Epoch 82/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0348 - val_loss: 0.0369\n",
      "Epoch 83/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0345 - val_loss: 0.0367\n",
      "Epoch 84/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0343 - val_loss: 0.0364\n",
      "Epoch 85/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0341 - val_loss: 0.0362\n",
      "Epoch 86/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0338 - val_loss: 0.0360\n",
      "Epoch 87/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0336 - val_loss: 0.0358\n",
      "Epoch 88/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0334 - val_loss: 0.0356\n",
      "Epoch 89/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0332 - val_loss: 0.0354\n",
      "Epoch 90/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0330 - val_loss: 0.0352\n",
      "Epoch 91/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0328 - val_loss: 0.0351\n",
      "Epoch 92/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0326 - val_loss: 0.0349\n",
      "Epoch 93/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0324 - val_loss: 0.0347\n",
      "Epoch 94/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0322 - val_loss: 0.0346\n",
      "Epoch 95/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0321 - val_loss: 0.0344\n",
      "Epoch 96/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0319 - val_loss: 0.0343\n",
      "Epoch 97/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0317 - val_loss: 0.0341\n",
      "Epoch 98/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0315 - val_loss: 0.0340\n",
      "Epoch 99/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0314 - val_loss: 0.0338\n",
      "Epoch 100/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0312 - val_loss: 0.0337\n",
      "Epoch 101/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0311 - val_loss: 0.0336\n",
      "Epoch 102/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0309 - val_loss: 0.0335\n",
      "Epoch 103/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0308 - val_loss: 0.0333\n",
      "Epoch 104/200\n",
      "614/614 [==============================] - 0s 33us/step - loss: 0.0306 - val_loss: 0.0332\n",
      "Epoch 105/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0305 - val_loss: 0.0331\n",
      "Epoch 106/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0303 - val_loss: 0.0330\n",
      "Epoch 107/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0302 - val_loss: 0.0329\n",
      "Epoch 108/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0300 - val_loss: 0.0328\n",
      "Epoch 109/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0299 - val_loss: 0.0327\n",
      "Epoch 110/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0298 - val_loss: 0.0326\n",
      "Epoch 111/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0296 - val_loss: 0.0325\n",
      "Epoch 112/200\n",
      "614/614 [==============================] - 0s 27us/step - loss: 0.0295 - val_loss: 0.0324\n",
      "Epoch 113/200\n",
      "614/614 [==============================] - 0s 24us/step - loss: 0.0294 - val_loss: 0.0323\n",
      "Epoch 114/200\n",
      "614/614 [==============================] - 0s 31us/step - loss: 0.0293 - val_loss: 0.0322\n",
      "Epoch 115/200\n",
      "614/614 [==============================] - 0s 33us/step - loss: 0.0292 - val_loss: 0.0321\n",
      "Epoch 116/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0290 - val_loss: 0.0320\n",
      "Epoch 117/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0289 - val_loss: 0.0319\n",
      "Epoch 118/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0288 - val_loss: 0.0319\n",
      "Epoch 119/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0287 - val_loss: 0.0318\n",
      "Epoch 120/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0286 - val_loss: 0.0317\n",
      "Epoch 121/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0285 - val_loss: 0.0316\n",
      "Epoch 122/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0284 - val_loss: 0.0316\n",
      "Epoch 123/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0283 - val_loss: 0.0315\n",
      "Epoch 124/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0282 - val_loss: 0.0314\n",
      "Epoch 125/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0281 - val_loss: 0.0314\n",
      "Epoch 126/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0280 - val_loss: 0.0313\n",
      "Epoch 127/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0279 - val_loss: 0.0312\n",
      "Epoch 128/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0278 - val_loss: 0.0312\n",
      "Epoch 129/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0277 - val_loss: 0.0311\n",
      "Epoch 130/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0276 - val_loss: 0.0311\n",
      "Epoch 131/200\n",
      "614/614 [==============================] - 0s 41us/step - loss: 0.0275 - val_loss: 0.0310\n",
      "Epoch 132/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0274 - val_loss: 0.0309\n",
      "Epoch 133/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0273 - val_loss: 0.0309\n",
      "Epoch 134/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0272 - val_loss: 0.0308\n",
      "Epoch 135/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0272 - val_loss: 0.0308\n",
      "Epoch 136/200\n",
      "614/614 [==============================] - 0s 33us/step - loss: 0.0271 - val_loss: 0.0307\n",
      "Epoch 137/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0270 - val_loss: 0.0307\n",
      "Epoch 138/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0269 - val_loss: 0.0306\n",
      "Epoch 139/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0268 - val_loss: 0.0306\n",
      "Epoch 140/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0268 - val_loss: 0.0305\n",
      "Epoch 141/200\n",
      "614/614 [==============================] - 0s 31us/step - loss: 0.0267 - val_loss: 0.0305\n",
      "Epoch 142/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0266 - val_loss: 0.0304\n",
      "Epoch 143/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0266 - val_loss: 0.0304\n",
      "Epoch 144/200\n",
      "614/614 [==============================] - 0s 32us/step - loss: 0.0265 - val_loss: 0.0304\n",
      "Epoch 145/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0264 - val_loss: 0.0303\n",
      "Epoch 146/200\n",
      "614/614 [==============================] - 0s 33us/step - loss: 0.0264 - val_loss: 0.0303\n",
      "Epoch 147/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0263 - val_loss: 0.0302\n",
      "Epoch 148/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0262 - val_loss: 0.0302\n",
      "Epoch 149/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0262 - val_loss: 0.0302\n",
      "Epoch 150/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0261 - val_loss: 0.0301\n",
      "Epoch 151/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0260 - val_loss: 0.0301\n",
      "Epoch 152/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0260 - val_loss: 0.0300\n",
      "Epoch 153/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0259 - val_loss: 0.0300\n",
      "Epoch 154/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0258 - val_loss: 0.0300\n",
      "Epoch 155/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0258 - val_loss: 0.0299\n",
      "Epoch 156/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0257 - val_loss: 0.0299\n",
      "Epoch 157/200\n",
      "614/614 [==============================] - 0s 28us/step - loss: 0.0257 - val_loss: 0.0299\n",
      "Epoch 158/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0256 - val_loss: 0.0298\n",
      "Epoch 159/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614/614 [==============================] - 0s 36us/step - loss: 0.0256 - val_loss: 0.0298\n",
      "Epoch 160/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0255 - val_loss: 0.0298\n",
      "Epoch 161/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0254 - val_loss: 0.0297\n",
      "Epoch 162/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0254 - val_loss: 0.0297\n",
      "Epoch 163/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0253 - val_loss: 0.0297\n",
      "Epoch 164/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0253 - val_loss: 0.0296\n",
      "Epoch 165/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0252 - val_loss: 0.0296\n",
      "Epoch 166/200\n",
      "614/614 [==============================] - 0s 39us/step - loss: 0.0252 - val_loss: 0.0296\n",
      "Epoch 167/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0251 - val_loss: 0.0295\n",
      "Epoch 168/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0251 - val_loss: 0.0295\n",
      "Epoch 169/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0250 - val_loss: 0.0295\n",
      "Epoch 170/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0250 - val_loss: 0.0295\n",
      "Epoch 171/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0249 - val_loss: 0.0294\n",
      "Epoch 172/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0249 - val_loss: 0.0294\n",
      "Epoch 173/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0248 - val_loss: 0.0294\n",
      "Epoch 174/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0248 - val_loss: 0.0293\n",
      "Epoch 175/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0248 - val_loss: 0.0293\n",
      "Epoch 176/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0247 - val_loss: 0.0293\n",
      "Epoch 177/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0247 - val_loss: 0.0293\n",
      "Epoch 178/200\n",
      "614/614 [==============================] - 0s 33us/step - loss: 0.0246 - val_loss: 0.0292\n",
      "Epoch 179/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0246 - val_loss: 0.0292\n",
      "Epoch 180/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0245 - val_loss: 0.0292\n",
      "Epoch 181/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0245 - val_loss: 0.0292\n",
      "Epoch 182/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0245 - val_loss: 0.0291\n",
      "Epoch 183/200\n",
      "614/614 [==============================] - 0s 32us/step - loss: 0.0244 - val_loss: 0.0291\n",
      "Epoch 184/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0244 - val_loss: 0.0291\n",
      "Epoch 185/200\n",
      "614/614 [==============================] - 0s 36us/step - loss: 0.0243 - val_loss: 0.0291\n",
      "Epoch 186/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0243 - val_loss: 0.0290\n",
      "Epoch 187/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0243 - val_loss: 0.0290\n",
      "Epoch 188/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0242 - val_loss: 0.0290\n",
      "Epoch 189/200\n",
      "614/614 [==============================] - 0s 32us/step - loss: 0.0242 - val_loss: 0.0290\n",
      "Epoch 190/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0241 - val_loss: 0.0289\n",
      "Epoch 191/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0241 - val_loss: 0.0289\n",
      "Epoch 192/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0241 - val_loss: 0.0289\n",
      "Epoch 193/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0240 - val_loss: 0.0289\n",
      "Epoch 194/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0240 - val_loss: 0.0289\n",
      "Epoch 195/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0240 - val_loss: 0.0288\n",
      "Epoch 196/200\n",
      "614/614 [==============================] - 0s 38us/step - loss: 0.0239 - val_loss: 0.0288\n",
      "Epoch 197/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0239 - val_loss: 0.0288\n",
      "Epoch 198/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0239 - val_loss: 0.0288\n",
      "Epoch 199/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0238 - val_loss: 0.0288\n",
      "Epoch 200/200\n",
      "614/614 [==============================] - 0s 33us/step - loss: 0.0238 - val_loss: 0.0287\n"
     ]
    }
   ],
   "source": [
    "############ Denoiding Autoencoder ###########\n",
    "\n",
    "# add noise\n",
    "noise_factor = 0.5\n",
    "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \n",
    "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \n",
    "\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
    "\n",
    "input_dim = x_train.shape[1]\n",
    "input_layer = Input(shape=(input_dim, ))\n",
    "\n",
    "encoding_dim = 12\n",
    "#learning_rate = 1e-7\n",
    "\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "\n",
    "decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
    "\n",
    "# implenment an autoencoder, creat encoder and decoder\n",
    "\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "\n",
    "encoder = Model(input_layer, encoded)\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "                                             \n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "ae_train = autoencoder.fit(x_train_noisy, x_train,\n",
    "                epochs=200,\n",
    "                batch_size=128,\n",
    "                shuffle=False,\n",
    "                validation_data=(x_test_noisy, x_test)\n",
    "                ).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DAE loss\n",
    "plt.plot(ae_train['loss'])\n",
    "plt.plot(ae_train['val_loss'])\n",
    "plt.title('DAE model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.035137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.010578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.023782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.026075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.031141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.043134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.062614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  200.000000\n",
       "mean     0.035137\n",
       "std      0.010578\n",
       "min      0.023782\n",
       "25%      0.026075\n",
       "50%      0.031141\n",
       "75%      0.043134\n",
       "max      0.062614"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = pd.DataFrame(ae_train['loss'])\n",
    "loss.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.037774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.009123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.028743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.030109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.033641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.044790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.061320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  200.000000\n",
       "mean     0.037774\n",
       "std      0.009123\n",
       "min      0.028743\n",
       "25%      0.030109\n",
       "50%      0.033641\n",
       "75%      0.044790\n",
       "max      0.061320"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss = pd.DataFrame(ae_train['val_loss'])\n",
    "val_loss.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create encoded data\n",
    "encoded_data = encoder.predict(x_test)\n",
    "#decoded_data = decoder.predict(encoded_data)\n",
    "\n",
    "# transform to SOM input type\n",
    "encoded_som = pd.DataFrame(encoded_data)\n",
    "#decoded_som = pd.DataFrame(decoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9821817"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>3.267661</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.659051</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.420627</td>\n",
       "      <td>0.877191</td>\n",
       "      <td>1.914744</td>\n",
       "      <td>1.734357</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.879234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>3.078229</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.648251</td>\n",
       "      <td>1.449205</td>\n",
       "      <td>3.801242</td>\n",
       "      <td>1.847487</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.699434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.162422</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>2.075658</td>\n",
       "      <td>1.709552</td>\n",
       "      <td>3.065782</td>\n",
       "      <td>2.461463</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.426339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.189977</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.683508</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.840549</td>\n",
       "      <td>2.455914</td>\n",
       "      <td>1.065598</td>\n",
       "      <td>0.563319</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.451205</td>\n",
       "      <td>3.930484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014068</td>\n",
       "      <td>2.062477</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.200067</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>3.061901</td>\n",
       "      <td>2.570292</td>\n",
       "      <td>1.469035</td>\n",
       "      <td>0.562991</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.127679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1    2         3    4         5         6         7   \\\n",
       "0 -0.000000  3.267661 -0.0  1.659051 -0.0  1.420627  0.877191  1.914744   \n",
       "1 -0.000000 -0.000000 -0.0  3.078229 -0.0  0.648251  1.449205  3.801242   \n",
       "2 -0.000000 -0.000000 -0.0  0.162422 -0.0  2.075658  1.709552  3.065782   \n",
       "3 -0.000000  0.189977 -0.0  0.683508 -0.0  1.840549  2.455914  1.065598   \n",
       "4  0.014068  2.062477 -0.0  1.200067 -0.0  3.061901  2.570292  1.469035   \n",
       "\n",
       "         8    9         10        11  \n",
       "0  1.734357 -0.0 -0.000000  1.879234  \n",
       "1  1.847487 -0.0 -0.000000  0.699434  \n",
       "2  2.461463 -0.0 -0.000000  1.426339  \n",
       "3  0.563319 -0.0  0.451205  3.930484  \n",
       "4  0.562991 -0.0 -0.000000  0.127679  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_som.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>3.252519</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.664136</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.413815</td>\n",
       "      <td>0.866405</td>\n",
       "      <td>1.924757</td>\n",
       "      <td>1.727526</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.881566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.114449</td>\n",
       "      <td>0.183713</td>\n",
       "      <td>1.324225</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.033902</td>\n",
       "      <td>2.740770</td>\n",
       "      <td>2.486386</td>\n",
       "      <td>0.550868</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>3.165959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.215400</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.805599</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>2.416831</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.893669</td>\n",
       "      <td>1.963711</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.893533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.001236</td>\n",
       "      <td>2.101959</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.211667</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>3.043216</td>\n",
       "      <td>2.603950</td>\n",
       "      <td>1.454819</td>\n",
       "      <td>0.545969</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.126178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>3.275495</td>\n",
       "      <td>0.182158</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>2.205590</td>\n",
       "      <td>1.239869</td>\n",
       "      <td>2.057195</td>\n",
       "      <td>1.004302</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.597937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3    4         5         6   \\\n",
       "405 -0.000000  3.252519 -0.000000  1.664136 -0.0  1.413815  0.866405   \n",
       "406 -0.000000  0.114449  0.183713  1.324225 -0.0  0.033902  2.740770   \n",
       "407 -0.000000  1.215400 -0.000000  1.805599 -0.0  2.416831 -0.000000   \n",
       "408  0.001236  2.101959 -0.000000  1.211667 -0.0  3.043216  2.603950   \n",
       "409 -0.000000 -0.000000  3.275495  0.182158 -0.0  2.205590  1.239869   \n",
       "\n",
       "           7         8    9    10        11  \n",
       "405  1.924757  1.727526 -0.0 -0.0  1.881566  \n",
       "406  2.486386  0.550868 -0.0 -0.0  3.165959  \n",
       "407  1.893669  1.963711 -0.0 -0.0  0.893533  \n",
       "408  1.454819  0.545969 -0.0 -0.0  0.126178  \n",
       "409  2.057195  1.004302 -0.0 -0.0  1.597937  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonzero = list(map(lambda i: any(encoded_data[:,i] != 0), range(encoded_data.shape[1])))\n",
    "\n",
    "encoded_som_nonzero = pd.DataFrame(encoded_data[:,nonzero])\n",
    "\n",
    "encoded_som_nonzero.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_som_nonzero.to_csv(path_or_buf='output/dim064_DAE_encoded.csv',index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:4: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:6: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "input_dim = x_train.shape[1]\n",
    "\n",
    "# tranform the input format, add a dimension\n",
    "x_train_con = x_train.as_matrix()\n",
    "x_train_con = np.reshape(x_train_con, (-1, input_dim, 1))\n",
    "x_text_con = x_test.as_matrix()\n",
    "x_text_con = np.reshape(x_text_con, (-1, input_dim, 1))\n",
    "\n",
    "input_layer = Input(shape=(input_dim,1))\n",
    "\n",
    "x = Conv1D(32, 3, activation='relu', padding='same')(input_layer)\n",
    "x = MaxPooling1D(4, padding='same')(x)\n",
    "x = Conv1D(16, 3, activation='relu', padding='same')(x)\n",
    "x = MaxPooling1D(4, padding='same')(x)\n",
    "x = Conv1D(4, 3, activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling1D(2, padding='same')(x)\n",
    "\n",
    "\n",
    "x = Conv1D(4, 3, activation='relu', padding='same')(encoded)\n",
    "x = UpSampling1D(2)(x)\n",
    "x = Conv1D(16, 3, activation='relu', padding='same')(x)\n",
    "x = UpSampling1D(4)(x)\n",
    "x = Conv1D(32, 3, activation='relu', padding='same')(x)\n",
    "x = UpSampling1D(4)(x)\n",
    "decoded = Conv1D(1, 1, activation='sigmoid')(x)\n",
    "\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "encoder = Model(input_layer, encoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 64, 1)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 64, 32)            128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 16, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 16, 16)            1552      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 4, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 4, 4)              196       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 2, 4)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 2, 4)              52        \n",
      "_________________________________________________________________\n",
      "up_sampling1d_1 (UpSampling1 (None, 4, 4)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 4, 16)             208       \n",
      "_________________________________________________________________\n",
      "up_sampling1d_2 (UpSampling1 (None, 16, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 16, 32)            1568      \n",
      "_________________________________________________________________\n",
      "up_sampling1d_3 (UpSampling1 (None, 64, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 64, 1)             33        \n",
      "=================================================================\n",
      "Total params: 3,737\n",
      "Trainable params: 3,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 614 samples, validate on 410 samples\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/200\n",
      "614/614 [==============================] - 3s 4ms/step - loss: 0.0579 - val_loss: 0.0575\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/callbacks.py:995: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n",
      "Epoch 2/200\n",
      "614/614 [==============================] - 0s 237us/step - loss: 0.0569 - val_loss: 0.0565\n",
      "Epoch 3/200\n",
      "614/614 [==============================] - 0s 228us/step - loss: 0.0559 - val_loss: 0.0557\n",
      "Epoch 4/200\n",
      "614/614 [==============================] - 0s 227us/step - loss: 0.0554 - val_loss: 0.0557\n",
      "Epoch 5/200\n",
      "614/614 [==============================] - 0s 234us/step - loss: 0.0553 - val_loss: 0.0556\n",
      "Epoch 6/200\n",
      "614/614 [==============================] - 0s 233us/step - loss: 0.0552 - val_loss: 0.0555\n",
      "Epoch 7/200\n",
      "614/614 [==============================] - 0s 225us/step - loss: 0.0551 - val_loss: 0.0554\n",
      "Epoch 8/200\n",
      "614/614 [==============================] - 0s 235us/step - loss: 0.0550 - val_loss: 0.0554\n",
      "Epoch 9/200\n",
      "614/614 [==============================] - 0s 240us/step - loss: 0.0550 - val_loss: 0.0553\n",
      "Epoch 10/200\n",
      "614/614 [==============================] - 0s 238us/step - loss: 0.0549 - val_loss: 0.0553\n",
      "Epoch 11/200\n",
      "614/614 [==============================] - 0s 226us/step - loss: 0.0549 - val_loss: 0.0552\n",
      "Epoch 12/200\n",
      "614/614 [==============================] - 0s 218us/step - loss: 0.0548 - val_loss: 0.0552\n",
      "Epoch 13/200\n",
      "614/614 [==============================] - 0s 216us/step - loss: 0.0548 - val_loss: 0.0551\n",
      "Epoch 14/200\n",
      "614/614 [==============================] - 0s 252us/step - loss: 0.0547 - val_loss: 0.0551\n",
      "Epoch 15/200\n",
      "614/614 [==============================] - 0s 211us/step - loss: 0.0547 - val_loss: 0.0550\n",
      "Epoch 16/200\n",
      "614/614 [==============================] - 0s 221us/step - loss: 0.0546 - val_loss: 0.0550\n",
      "Epoch 17/200\n",
      "614/614 [==============================] - 0s 214us/step - loss: 0.0545 - val_loss: 0.0549\n",
      "Epoch 18/200\n",
      "614/614 [==============================] - 0s 232us/step - loss: 0.0545 - val_loss: 0.0548\n",
      "Epoch 19/200\n",
      "614/614 [==============================] - 0s 212us/step - loss: 0.0544 - val_loss: 0.0547\n",
      "Epoch 20/200\n",
      "614/614 [==============================] - 0s 203us/step - loss: 0.0543 - val_loss: 0.0547\n",
      "Epoch 21/200\n",
      "614/614 [==============================] - 0s 217us/step - loss: 0.0542 - val_loss: 0.0546\n",
      "Epoch 22/200\n",
      "614/614 [==============================] - 0s 218us/step - loss: 0.0542 - val_loss: 0.0545\n",
      "Epoch 23/200\n",
      "614/614 [==============================] - 0s 214us/step - loss: 0.0540 - val_loss: 0.0544\n",
      "Epoch 24/200\n",
      "614/614 [==============================] - 0s 217us/step - loss: 0.0539 - val_loss: 0.0543\n",
      "Epoch 25/200\n",
      "614/614 [==============================] - 0s 225us/step - loss: 0.0538 - val_loss: 0.0541\n",
      "Epoch 26/200\n",
      "614/614 [==============================] - 0s 212us/step - loss: 0.0537 - val_loss: 0.0540\n",
      "Epoch 27/200\n",
      "614/614 [==============================] - 0s 214us/step - loss: 0.0535 - val_loss: 0.0538\n",
      "Epoch 28/200\n",
      "614/614 [==============================] - 0s 217us/step - loss: 0.0534 - val_loss: 0.0536\n",
      "Epoch 29/200\n",
      "614/614 [==============================] - 0s 206us/step - loss: 0.0532 - val_loss: 0.0534\n",
      "Epoch 30/200\n",
      "614/614 [==============================] - 0s 213us/step - loss: 0.0529 - val_loss: 0.0532\n",
      "Epoch 31/200\n",
      "614/614 [==============================] - 0s 214us/step - loss: 0.0527 - val_loss: 0.0530\n",
      "Epoch 32/200\n",
      "614/614 [==============================] - 0s 214us/step - loss: 0.0525 - val_loss: 0.0528\n",
      "Epoch 33/200\n",
      "614/614 [==============================] - 0s 211us/step - loss: 0.0524 - val_loss: 0.0527\n",
      "Epoch 34/200\n",
      "614/614 [==============================] - 0s 218us/step - loss: 0.0523 - val_loss: 0.0526\n",
      "Epoch 35/200\n",
      "614/614 [==============================] - 0s 214us/step - loss: 0.0521 - val_loss: 0.0525\n",
      "Epoch 36/200\n",
      "614/614 [==============================] - 0s 214us/step - loss: 0.0520 - val_loss: 0.0524\n",
      "Epoch 37/200\n",
      "614/614 [==============================] - 0s 216us/step - loss: 0.0519 - val_loss: 0.0522\n",
      "Epoch 38/200\n",
      "614/614 [==============================] - 0s 227us/step - loss: 0.0518 - val_loss: 0.0522\n",
      "Epoch 39/200\n",
      "614/614 [==============================] - 0s 214us/step - loss: 0.0517 - val_loss: 0.0521\n",
      "Epoch 40/200\n",
      "614/614 [==============================] - 0s 208us/step - loss: 0.0517 - val_loss: 0.0520\n",
      "Epoch 41/200\n",
      "614/614 [==============================] - 0s 217us/step - loss: 0.0516 - val_loss: 0.0519\n",
      "Epoch 42/200\n",
      "614/614 [==============================] - 0s 221us/step - loss: 0.0515 - val_loss: 0.0519\n",
      "Epoch 43/200\n",
      "614/614 [==============================] - 0s 218us/step - loss: 0.0515 - val_loss: 0.0518\n",
      "Epoch 44/200\n",
      "614/614 [==============================] - 0s 220us/step - loss: 0.0514 - val_loss: 0.0518\n",
      "Epoch 45/200\n",
      "614/614 [==============================] - 0s 215us/step - loss: 0.0513 - val_loss: 0.0517\n",
      "Epoch 46/200\n",
      "614/614 [==============================] - 0s 214us/step - loss: 0.0513 - val_loss: 0.0517\n",
      "Epoch 47/200\n",
      "614/614 [==============================] - 0s 213us/step - loss: 0.0512 - val_loss: 0.0516\n",
      "Epoch 48/200\n",
      "614/614 [==============================] - 0s 220us/step - loss: 0.0512 - val_loss: 0.0515\n",
      "Epoch 49/200\n",
      "614/614 [==============================] - 0s 204us/step - loss: 0.0511 - val_loss: 0.0515\n",
      "Epoch 50/200\n",
      "614/614 [==============================] - 0s 213us/step - loss: 0.0511 - val_loss: 0.0514\n",
      "Epoch 51/200\n",
      "614/614 [==============================] - 0s 215us/step - loss: 0.0510 - val_loss: 0.0514\n",
      "Epoch 52/200\n",
      "614/614 [==============================] - 0s 218us/step - loss: 0.0510 - val_loss: 0.0514\n",
      "Epoch 53/200\n",
      "614/614 [==============================] - 0s 221us/step - loss: 0.0509 - val_loss: 0.0513\n",
      "Epoch 54/200\n",
      "614/614 [==============================] - 0s 213us/step - loss: 0.0508 - val_loss: 0.0512\n",
      "Epoch 55/200\n",
      "614/614 [==============================] - 0s 208us/step - loss: 0.0508 - val_loss: 0.0512\n",
      "Epoch 56/200\n",
      "614/614 [==============================] - 0s 215us/step - loss: 0.0507 - val_loss: 0.0511\n",
      "Epoch 57/200\n",
      "614/614 [==============================] - 0s 213us/step - loss: 0.0506 - val_loss: 0.0510\n",
      "Epoch 58/200\n",
      "614/614 [==============================] - 0s 215us/step - loss: 0.0506 - val_loss: 0.0510\n",
      "Epoch 59/200\n",
      "614/614 [==============================] - 0s 214us/step - loss: 0.0505 - val_loss: 0.0509\n",
      "Epoch 60/200\n",
      "614/614 [==============================] - 0s 214us/step - loss: 0.0504 - val_loss: 0.0508\n",
      "Epoch 61/200\n",
      "614/614 [==============================] - 0s 219us/step - loss: 0.0503 - val_loss: 0.0508\n",
      "Epoch 62/200\n",
      "614/614 [==============================] - 0s 216us/step - loss: 0.0503 - val_loss: 0.0507\n",
      "Epoch 63/200\n",
      "614/614 [==============================] - 0s 222us/step - loss: 0.0502 - val_loss: 0.0506\n",
      "Epoch 64/200\n",
      "614/614 [==============================] - 0s 221us/step - loss: 0.0501 - val_loss: 0.0505\n",
      "Epoch 65/200\n",
      "614/614 [==============================] - 0s 223us/step - loss: 0.0501 - val_loss: 0.0505\n",
      "Epoch 66/200\n",
      "614/614 [==============================] - 0s 225us/step - loss: 0.0500 - val_loss: 0.0504\n",
      "Epoch 67/200\n",
      "614/614 [==============================] - 0s 224us/step - loss: 0.0499 - val_loss: 0.0503\n",
      "Epoch 68/200\n",
      "614/614 [==============================] - 0s 219us/step - loss: 0.0498 - val_loss: 0.0503\n",
      "Epoch 69/200\n",
      "614/614 [==============================] - 0s 221us/step - loss: 0.0498 - val_loss: 0.0502\n",
      "Epoch 70/200\n",
      "614/614 [==============================] - 0s 216us/step - loss: 0.0497 - val_loss: 0.0501\n",
      "Epoch 71/200\n",
      "614/614 [==============================] - 0s 216us/step - loss: 0.0497 - val_loss: 0.0501\n",
      "Epoch 72/200\n",
      "614/614 [==============================] - 0s 250us/step - loss: 0.0496 - val_loss: 0.0500\n",
      "Epoch 73/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614/614 [==============================] - 0s 229us/step - loss: 0.0496 - val_loss: 0.0500\n",
      "Epoch 74/200\n",
      "614/614 [==============================] - 0s 211us/step - loss: 0.0495 - val_loss: 0.0499\n",
      "Epoch 75/200\n",
      "614/614 [==============================] - 0s 218us/step - loss: 0.0495 - val_loss: 0.0499\n",
      "Epoch 76/200\n",
      "614/614 [==============================] - 0s 225us/step - loss: 0.0494 - val_loss: 0.0499\n",
      "Epoch 77/200\n",
      "614/614 [==============================] - 0s 224us/step - loss: 0.0494 - val_loss: 0.0498\n",
      "Epoch 78/200\n",
      "614/614 [==============================] - 0s 225us/step - loss: 0.0493 - val_loss: 0.0498\n",
      "Epoch 79/200\n",
      "614/614 [==============================] - 0s 222us/step - loss: 0.0493 - val_loss: 0.0497\n",
      "Epoch 80/200\n",
      "614/614 [==============================] - 0s 232us/step - loss: 0.0493 - val_loss: 0.0497\n",
      "Epoch 81/200\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.049 - 0s 245us/step - loss: 0.0492 - val_loss: 0.0496\n",
      "Epoch 82/200\n",
      "614/614 [==============================] - 0s 255us/step - loss: 0.0492 - val_loss: 0.0496\n",
      "Epoch 83/200\n",
      "614/614 [==============================] - 0s 440us/step - loss: 0.0491 - val_loss: 0.0495\n",
      "Epoch 84/200\n",
      "614/614 [==============================] - 0s 522us/step - loss: 0.0491 - val_loss: 0.0495\n",
      "Epoch 85/200\n",
      "614/614 [==============================] - 0s 536us/step - loss: 0.0490 - val_loss: 0.0495\n",
      "Epoch 86/200\n",
      "614/614 [==============================] - 0s 351us/step - loss: 0.0490 - val_loss: 0.0494\n",
      "Epoch 87/200\n",
      "614/614 [==============================] - 0s 239us/step - loss: 0.0489 - val_loss: 0.0494\n",
      "Epoch 88/200\n",
      "614/614 [==============================] - 0s 242us/step - loss: 0.0489 - val_loss: 0.0493\n",
      "Epoch 89/200\n",
      "614/614 [==============================] - 0s 230us/step - loss: 0.0489 - val_loss: 0.0493\n",
      "Epoch 90/200\n",
      "614/614 [==============================] - 0s 230us/step - loss: 0.0488 - val_loss: 0.0492\n",
      "Epoch 91/200\n",
      "614/614 [==============================] - 0s 226us/step - loss: 0.0488 - val_loss: 0.0492\n",
      "Epoch 92/200\n",
      "614/614 [==============================] - 0s 226us/step - loss: 0.0487 - val_loss: 0.0492\n",
      "Epoch 93/200\n",
      "614/614 [==============================] - 0s 224us/step - loss: 0.0487 - val_loss: 0.0491\n",
      "Epoch 94/200\n",
      "614/614 [==============================] - 0s 220us/step - loss: 0.0487 - val_loss: 0.0491\n",
      "Epoch 95/200\n",
      "614/614 [==============================] - 0s 223us/step - loss: 0.0486 - val_loss: 0.0491\n",
      "Epoch 96/200\n",
      "614/614 [==============================] - 0s 227us/step - loss: 0.0486 - val_loss: 0.0490\n",
      "Epoch 97/200\n",
      "614/614 [==============================] - 0s 222us/step - loss: 0.0486 - val_loss: 0.0490\n",
      "Epoch 98/200\n",
      "614/614 [==============================] - 0s 217us/step - loss: 0.0485 - val_loss: 0.0490\n",
      "Epoch 99/200\n",
      "614/614 [==============================] - 0s 228us/step - loss: 0.0485 - val_loss: 0.0489\n",
      "Epoch 100/200\n",
      "614/614 [==============================] - 0s 224us/step - loss: 0.0484 - val_loss: 0.0489\n",
      "Epoch 101/200\n",
      "614/614 [==============================] - 0s 221us/step - loss: 0.0484 - val_loss: 0.0488\n",
      "Epoch 102/200\n",
      "614/614 [==============================] - 0s 226us/step - loss: 0.0484 - val_loss: 0.0488\n",
      "Epoch 103/200\n",
      "614/614 [==============================] - 0s 221us/step - loss: 0.0483 - val_loss: 0.0488\n",
      "Epoch 104/200\n",
      "614/614 [==============================] - 0s 216us/step - loss: 0.0483 - val_loss: 0.0487\n",
      "Epoch 105/200\n",
      "614/614 [==============================] - 0s 219us/step - loss: 0.0482 - val_loss: 0.0487\n",
      "Epoch 106/200\n",
      "614/614 [==============================] - 0s 220us/step - loss: 0.0482 - val_loss: 0.0486\n",
      "Epoch 107/200\n",
      "614/614 [==============================] - 0s 225us/step - loss: 0.0482 - val_loss: 0.0486\n",
      "Epoch 108/200\n",
      "614/614 [==============================] - 0s 228us/step - loss: 0.0481 - val_loss: 0.0486\n",
      "Epoch 109/200\n",
      "614/614 [==============================] - 0s 221us/step - loss: 0.0481 - val_loss: 0.0485\n",
      "Epoch 110/200\n",
      "614/614 [==============================] - 0s 220us/step - loss: 0.0481 - val_loss: 0.0485\n",
      "Epoch 111/200\n",
      "614/614 [==============================] - 0s 220us/step - loss: 0.0480 - val_loss: 0.0485\n",
      "Epoch 112/200\n",
      "614/614 [==============================] - 0s 220us/step - loss: 0.0480 - val_loss: 0.0484\n",
      "Epoch 113/200\n",
      "614/614 [==============================] - 0s 211us/step - loss: 0.0479 - val_loss: 0.0484\n",
      "Epoch 114/200\n",
      "614/614 [==============================] - 0s 224us/step - loss: 0.0479 - val_loss: 0.0484\n",
      "Epoch 115/200\n",
      "614/614 [==============================] - 0s 218us/step - loss: 0.0479 - val_loss: 0.0483\n",
      "Epoch 116/200\n",
      "614/614 [==============================] - 0s 217us/step - loss: 0.0478 - val_loss: 0.0483\n",
      "Epoch 117/200\n",
      "614/614 [==============================] - 0s 218us/step - loss: 0.0478 - val_loss: 0.0482\n",
      "Epoch 118/200\n",
      "614/614 [==============================] - 0s 219us/step - loss: 0.0477 - val_loss: 0.0482\n",
      "Epoch 119/200\n",
      "614/614 [==============================] - 0s 219us/step - loss: 0.0477 - val_loss: 0.0482\n",
      "Epoch 120/200\n",
      "614/614 [==============================] - 0s 222us/step - loss: 0.0477 - val_loss: 0.0481\n",
      "Epoch 121/200\n",
      "614/614 [==============================] - 0s 218us/step - loss: 0.0476 - val_loss: 0.0481\n",
      "Epoch 122/200\n",
      "614/614 [==============================] - 0s 223us/step - loss: 0.0476 - val_loss: 0.0481\n",
      "Epoch 123/200\n",
      "614/614 [==============================] - 0s 217us/step - loss: 0.0476 - val_loss: 0.0480\n",
      "Epoch 124/200\n",
      "614/614 [==============================] - 0s 216us/step - loss: 0.0475 - val_loss: 0.0480\n",
      "Epoch 125/200\n",
      "614/614 [==============================] - 0s 213us/step - loss: 0.0475 - val_loss: 0.0480\n",
      "Epoch 126/200\n",
      "614/614 [==============================] - 0s 221us/step - loss: 0.0475 - val_loss: 0.0480\n",
      "Epoch 127/200\n",
      "614/614 [==============================] - 0s 224us/step - loss: 0.0474 - val_loss: 0.0479\n",
      "Epoch 128/200\n",
      "614/614 [==============================] - 0s 220us/step - loss: 0.0474 - val_loss: 0.0479\n",
      "Epoch 129/200\n",
      "614/614 [==============================] - 0s 220us/step - loss: 0.0474 - val_loss: 0.0479\n",
      "Epoch 130/200\n",
      "614/614 [==============================] - 0s 221us/step - loss: 0.0473 - val_loss: 0.0478\n",
      "Epoch 131/200\n",
      "614/614 [==============================] - 0s 217us/step - loss: 0.0473 - val_loss: 0.0478\n",
      "Epoch 132/200\n",
      "614/614 [==============================] - 0s 221us/step - loss: 0.0473 - val_loss: 0.0478\n",
      "Epoch 133/200\n",
      "614/614 [==============================] - 0s 218us/step - loss: 0.0472 - val_loss: 0.0477\n",
      "Epoch 134/200\n",
      "614/614 [==============================] - 0s 213us/step - loss: 0.0472 - val_loss: 0.0477\n",
      "Epoch 135/200\n",
      "614/614 [==============================] - 0s 216us/step - loss: 0.0472 - val_loss: 0.0477\n",
      "Epoch 136/200\n",
      "614/614 [==============================] - 0s 216us/step - loss: 0.0471 - val_loss: 0.0476\n",
      "Epoch 137/200\n",
      "614/614 [==============================] - 0s 223us/step - loss: 0.0471 - val_loss: 0.0476\n",
      "Epoch 138/200\n",
      "614/614 [==============================] - 0s 216us/step - loss: 0.0471 - val_loss: 0.0476\n",
      "Epoch 139/200\n",
      "614/614 [==============================] - 0s 214us/step - loss: 0.0471 - val_loss: 0.0476\n",
      "Epoch 140/200\n",
      "614/614 [==============================] - 0s 224us/step - loss: 0.0470 - val_loss: 0.0475\n",
      "Epoch 141/200\n",
      "614/614 [==============================] - 0s 215us/step - loss: 0.0470 - val_loss: 0.0475\n",
      "Epoch 142/200\n",
      "614/614 [==============================] - 0s 217us/step - loss: 0.0470 - val_loss: 0.0475\n",
      "Epoch 143/200\n",
      "614/614 [==============================] - 0s 221us/step - loss: 0.0469 - val_loss: 0.0475\n",
      "Epoch 144/200\n",
      "614/614 [==============================] - 0s 219us/step - loss: 0.0469 - val_loss: 0.0474\n",
      "Epoch 145/200\n",
      "614/614 [==============================] - 0s 220us/step - loss: 0.0469 - val_loss: 0.0474\n",
      "Epoch 146/200\n",
      "614/614 [==============================] - 0s 216us/step - loss: 0.0469 - val_loss: 0.0474\n",
      "Epoch 147/200\n",
      "614/614 [==============================] - 0s 227us/step - loss: 0.0468 - val_loss: 0.0474\n",
      "Epoch 148/200\n",
      "614/614 [==============================] - 0s 222us/step - loss: 0.0468 - val_loss: 0.0474\n",
      "Epoch 149/200\n",
      "614/614 [==============================] - 0s 221us/step - loss: 0.0468 - val_loss: 0.0473\n",
      "Epoch 150/200\n",
      "614/614 [==============================] - 0s 220us/step - loss: 0.0468 - val_loss: 0.0473\n",
      "Epoch 151/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614/614 [==============================] - 0s 225us/step - loss: 0.0468 - val_loss: 0.0473\n",
      "Epoch 152/200\n",
      "614/614 [==============================] - 0s 225us/step - loss: 0.0467 - val_loss: 0.0473\n",
      "Epoch 153/200\n",
      "614/614 [==============================] - 0s 228us/step - loss: 0.0467 - val_loss: 0.0472\n",
      "Epoch 154/200\n",
      "614/614 [==============================] - 0s 228us/step - loss: 0.0467 - val_loss: 0.0472\n",
      "Epoch 155/200\n",
      "614/614 [==============================] - 0s 223us/step - loss: 0.0467 - val_loss: 0.0472\n",
      "Epoch 156/200\n",
      "614/614 [==============================] - 0s 226us/step - loss: 0.0467 - val_loss: 0.0472\n",
      "Epoch 157/200\n",
      "614/614 [==============================] - 0s 214us/step - loss: 0.0466 - val_loss: 0.0472\n",
      "Epoch 158/200\n",
      "614/614 [==============================] - 0s 212us/step - loss: 0.0466 - val_loss: 0.0472\n",
      "Epoch 159/200\n",
      "614/614 [==============================] - 0s 221us/step - loss: 0.0466 - val_loss: 0.0472\n",
      "Epoch 160/200\n",
      "614/614 [==============================] - 0s 222us/step - loss: 0.0466 - val_loss: 0.0471\n",
      "Epoch 161/200\n",
      "614/614 [==============================] - 0s 214us/step - loss: 0.0466 - val_loss: 0.0471\n",
      "Epoch 162/200\n",
      "614/614 [==============================] - 0s 214us/step - loss: 0.0466 - val_loss: 0.0471\n",
      "Epoch 163/200\n",
      "614/614 [==============================] - 0s 219us/step - loss: 0.0466 - val_loss: 0.0471\n",
      "Epoch 164/200\n",
      "614/614 [==============================] - 0s 221us/step - loss: 0.0465 - val_loss: 0.0471\n",
      "Epoch 165/200\n",
      "614/614 [==============================] - 0s 222us/step - loss: 0.0465 - val_loss: 0.0471\n",
      "Epoch 166/200\n",
      "614/614 [==============================] - 0s 227us/step - loss: 0.0465 - val_loss: 0.0471\n",
      "Epoch 167/200\n",
      "614/614 [==============================] - 0s 220us/step - loss: 0.0465 - val_loss: 0.0470\n",
      "Epoch 168/200\n",
      "614/614 [==============================] - 0s 217us/step - loss: 0.0465 - val_loss: 0.0470\n",
      "Epoch 169/200\n",
      "614/614 [==============================] - 0s 222us/step - loss: 0.0465 - val_loss: 0.0470\n",
      "Epoch 170/200\n",
      "614/614 [==============================] - 0s 216us/step - loss: 0.0464 - val_loss: 0.0470\n",
      "Epoch 171/200\n",
      "614/614 [==============================] - 0s 216us/step - loss: 0.0464 - val_loss: 0.0470\n",
      "Epoch 172/200\n",
      "614/614 [==============================] - 0s 220us/step - loss: 0.0464 - val_loss: 0.0470\n",
      "Epoch 173/200\n",
      "614/614 [==============================] - 0s 224us/step - loss: 0.0464 - val_loss: 0.0469\n",
      "Epoch 174/200\n",
      "614/614 [==============================] - 0s 222us/step - loss: 0.0464 - val_loss: 0.0469\n",
      "Epoch 175/200\n",
      "614/614 [==============================] - 0s 219us/step - loss: 0.0464 - val_loss: 0.0469\n",
      "Epoch 176/200\n",
      "614/614 [==============================] - 0s 220us/step - loss: 0.0464 - val_loss: 0.0469\n",
      "Epoch 177/200\n",
      "614/614 [==============================] - 0s 232us/step - loss: 0.0464 - val_loss: 0.0469\n",
      "Epoch 178/200\n",
      "614/614 [==============================] - 0s 218us/step - loss: 0.0463 - val_loss: 0.0469\n",
      "Epoch 179/200\n",
      "614/614 [==============================] - 0s 225us/step - loss: 0.0463 - val_loss: 0.0469\n",
      "Epoch 180/200\n",
      "614/614 [==============================] - 0s 221us/step - loss: 0.0463 - val_loss: 0.0469\n",
      "Epoch 181/200\n",
      "614/614 [==============================] - 0s 219us/step - loss: 0.0463 - val_loss: 0.0469\n",
      "Epoch 182/200\n",
      "614/614 [==============================] - 0s 217us/step - loss: 0.0463 - val_loss: 0.0468\n",
      "Epoch 183/200\n",
      "614/614 [==============================] - 0s 220us/step - loss: 0.0463 - val_loss: 0.0468\n",
      "Epoch 184/200\n",
      "614/614 [==============================] - 0s 233us/step - loss: 0.0462 - val_loss: 0.0468\n",
      "Epoch 185/200\n",
      "614/614 [==============================] - 0s 224us/step - loss: 0.0462 - val_loss: 0.0468\n",
      "Epoch 186/200\n",
      "614/614 [==============================] - 0s 217us/step - loss: 0.0462 - val_loss: 0.0468\n",
      "Epoch 187/200\n",
      "614/614 [==============================] - 0s 217us/step - loss: 0.0462 - val_loss: 0.0468\n",
      "Epoch 188/200\n",
      "614/614 [==============================] - 0s 216us/step - loss: 0.0462 - val_loss: 0.0468\n",
      "Epoch 189/200\n",
      "614/614 [==============================] - 0s 224us/step - loss: 0.0462 - val_loss: 0.0467\n",
      "Epoch 190/200\n",
      "614/614 [==============================] - 0s 227us/step - loss: 0.0462 - val_loss: 0.0467\n",
      "Epoch 191/200\n",
      "614/614 [==============================] - 0s 221us/step - loss: 0.0462 - val_loss: 0.0467\n",
      "Epoch 192/200\n",
      "614/614 [==============================] - 0s 230us/step - loss: 0.0461 - val_loss: 0.0467\n",
      "Epoch 193/200\n",
      "614/614 [==============================] - 0s 228us/step - loss: 0.0461 - val_loss: 0.0467\n",
      "Epoch 194/200\n",
      "614/614 [==============================] - 0s 214us/step - loss: 0.0461 - val_loss: 0.0467\n",
      "Epoch 195/200\n",
      "614/614 [==============================] - 0s 211us/step - loss: 0.0461 - val_loss: 0.0467\n",
      "Epoch 196/200\n",
      "614/614 [==============================] - 0s 216us/step - loss: 0.0461 - val_loss: 0.0467\n",
      "Epoch 197/200\n",
      "614/614 [==============================] - 0s 217us/step - loss: 0.0461 - val_loss: 0.0466\n",
      "Epoch 198/200\n",
      "614/614 [==============================] - 0s 219us/step - loss: 0.0461 - val_loss: 0.0466\n",
      "Epoch 199/200\n",
      "614/614 [==============================] - 0s 216us/step - loss: 0.0460 - val_loss: 0.0466\n",
      "Epoch 200/200\n",
      "614/614 [==============================] - 0s 210us/step - loss: 0.0460 - val_loss: 0.0466\n"
     ]
    }
   ],
   "source": [
    "ae_train = autoencoder.fit(x_train_con, x_train_con,\n",
    "                epochs=200,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_text_con, x_text_con),\n",
    "                callbacks=[TensorBoard(log_dir='/tmp/autoencoder')]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Con_AE loss\n",
    "plt.plot(ae_train['loss'])\n",
    "plt.plot(ae_train['val_loss'])\n",
    "plt.title('Conv_AE model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.049235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.002876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.046034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.046772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.048422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.051031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.057876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  200.000000\n",
       "mean     0.049235\n",
       "std      0.002876\n",
       "min      0.046034\n",
       "25%      0.046772\n",
       "50%      0.048422\n",
       "75%      0.051031\n",
       "max      0.057876"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = pd.DataFrame(ae_train['loss'])\n",
    "loss.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.049674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.002774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.046602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.047300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.048859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.051417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.057497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  200.000000\n",
       "mean     0.049674\n",
       "std      0.002774\n",
       "min      0.046602\n",
       "25%      0.047300\n",
       "50%      0.048859\n",
       "75%      0.051417\n",
       "max      0.057497"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss = pd.DataFrame(ae_train['val_loss'])\n",
    "val_loss.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data = encoder.predict(x_text_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(410, 2, 4)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create encoded data\n",
    "\n",
    "encoded_data = encoded_data.reshape(-1, 2*4)\n",
    "\n",
    "# transform to SOM input type\n",
    "encoded_som = pd.DataFrame(encoded_data)\n",
    "#decoded_som = pd.DataFrame(decoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66401666"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>3.360027</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.287915</td>\n",
       "      <td>1.160248</td>\n",
       "      <td>0.616803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.466576</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.613625</td>\n",
       "      <td>2.414874</td>\n",
       "      <td>0.815550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>3.205820</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.102885</td>\n",
       "      <td>0.905530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>4.513686</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.301249</td>\n",
       "      <td>0.383365</td>\n",
       "      <td>0.758602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>2.008009</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.648849</td>\n",
       "      <td>1.422501</td>\n",
       "      <td>0.844985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1         2    3    4         5         6         7\n",
       "0 -0.0 -0.0  3.360027 -0.0 -0.0  1.287915  1.160248  0.616803\n",
       "1 -0.0 -0.0  1.466576 -0.0 -0.0  0.613625  2.414874  0.815550\n",
       "2 -0.0 -0.0  3.205820 -0.0 -0.0 -0.000000  1.102885  0.905530\n",
       "3 -0.0 -0.0  4.513686 -0.0 -0.0  0.301249  0.383365  0.758602\n",
       "4 -0.0 -0.0  2.008009 -0.0 -0.0  0.648849  1.422501  0.844985"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_som.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>3.350814</td>\n",
       "      <td>1.274927</td>\n",
       "      <td>1.140507</td>\n",
       "      <td>0.621154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>3.934119</td>\n",
       "      <td>0.319135</td>\n",
       "      <td>1.320077</td>\n",
       "      <td>0.710896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>2.167382</td>\n",
       "      <td>0.559387</td>\n",
       "      <td>1.212101</td>\n",
       "      <td>0.402231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>2.033900</td>\n",
       "      <td>0.646862</td>\n",
       "      <td>1.427816</td>\n",
       "      <td>0.845780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>2.123695</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.226861</td>\n",
       "      <td>0.407121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3\n",
       "405  3.350814  1.274927  1.140507  0.621154\n",
       "406  3.934119  0.319135  1.320077  0.710896\n",
       "407  2.167382  0.559387  1.212101  0.402231\n",
       "408  2.033900  0.646862  1.427816  0.845780\n",
       "409  2.123695 -0.000000  1.226861  0.407121"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonzero = list(map(lambda i: any(encoded_data[:,i] != 0), range(encoded_data.shape[1])))\n",
    "\n",
    "encoded_som_nonzero = pd.DataFrame(encoded_data[:,nonzero])\n",
    "\n",
    "encoded_som_nonzero.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_som_nonzero.to_csv(path_or_buf='output/dim064_ConAE_encoded.csv',index= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
